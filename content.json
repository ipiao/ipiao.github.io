[{"title":"Raft算法","date":"2020-03-19T10:05:00.000Z","path":"2020/03/19/Raft算法/","text":"Raft raft基本原理演示请参考 http://thesecretlivesofdata.com/raft/ go语言的raft实现 https://github.com/goraft/raft, 但是该项目早已不再维护，原作者将raft融入到etcd和influxdb(现在貌似不是了)里了，这里摘出etcd的raft实现进行研究 这是etcd/raft包的文档文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379 // Copyright 2015 The etcd Authors//// Licensed under the Apache License, Version 2.0 (the \"License\");// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an \"AS IS\" BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License./*Package raft sends and receives messages in the Protocol Buffer formatdefined in the raftpb package.Raft is a protocol with which a cluster of nodes can maintain a replicated state machine.The state machine is kept in sync through the use of a replicated log.For more details on Raft, see \"In Search of an Understandable Consensus Algorithm\"(https://ramcloud.stanford.edu/raft.pdf) by Diego Ongaro and John Ousterhout.A simple example application, _raftexample_, is also available to help illustratehow to use this package in practice:https://github.com/coreos/etcd/tree/master/contrib/raftexampleUsage# raft里面最的基础对象是NodeThe primary object in raft is a Node. You either start a Node from scratchusing raft.StartNode or start a Node from some initial state using raft.RestartNode.To start a node from scratch: storage := raft.NewMemoryStorage() c := &amp;Config&#123; ID: 0x01, ElectionTick: 10, HeartbeatTick: 1, Storage: storage, MaxSizePerMsg: 4096, MaxInflightMsgs: 256, &#125; n := raft.StartNode(c, []raft.Peer&#123;&#123;ID: 0x02&#125;, &#123;ID: 0x03&#125;&#125;)To restart a node from previous state: storage := raft.NewMemoryStorage() // recover the in-memory storage from persistent // snapshot, state and entries. storage.ApplySnapshot(snapshot) storage.SetHardState(state) storage.Append(entries) c := &amp;Config&#123; ID: 0x01, ElectionTick: 10, HeartbeatTick: 1, Storage: storage, MaxSizePerMsg: 4096, MaxInflightMsgs: 256, &#125; // restart raft without peer information. // peer information is already included in the storage. n := raft.RestartNode(c)# 现在你掌握了一个Node，你有些任务需要完成Now that you are holding onto a Node you have a few responsibilities:# 第一，你必须从 Node.Ready()通道读取数据，并要对其包含的更新进行操作，这步操作一般是并发的，除非遇到步骤二First, you must read from the Node.Ready() channel and process the updatesit contains. These steps may be performed in parallel, except as noted in step2.# 1. 将硬件状态，Entries(一个个数据实体)和Snapshot(快照)写入到持久化数据库，如果这些东西不是空的。注意，如果写入一个Entry的index是i，那之前持久的index大于i的Entries都将被忽略掉。1. Write HardState, Entries, and Snapshot to persistent storage if they arenot empty. Note that when writing an Entry with Index i, anypreviously-persisted entries with Index &gt;= i must be discarded.# 2. 将所有的消息发送给字段to里面的节点。这里关键的点是，在硬件状态同步到数据库之前，并且所有的Entries已经写入到之前准备好的batch中，消息将无法发送。为了减少I/O延迟，可以通过并发操作，将leader的数据同步给follwers。如果某条消息的类型是MsgSnap，在将数据发送出去之后需要调用 Node.ReportSnapshot2. Send all Messages to the nodes named in the To field. It is important thatno messages be sent until the latest HardState has been persisted to disk,and all Entries written by any previous Ready batch (Messages may be sent whileentries from the same batch are being persisted). To reduce the I/O latency, anoptimization can be applied to make leader write to disk in parallel with itsfollowers (as explained at section 10.2.1 in Raft thesis). If any Message has typeMsgSnap, call Node.ReportSnapshot() after it has been sent (these messages may belarge).# 注意: 编码消息不是并发安全的，所以很重要的一点是你要保证在消息编码的时候没有Entries持久化。最简单的处理方式就死直接在你的raft主循环里序列化消息Note: Marshalling messages is not thread-safe; it is important that youmake sure that no new entries are persisted while marshalling.The easiest way to achieve this is to serialise the messages directly insideyour main raft loop.# 3. 将Snapshot和已提交的Entries应用到状态机。如果已提交的Entry是类型EntryConfChange，调用Node.ApplyConfChange()来将它应用到节点。如果在调用ApplyConfChange之前将NodeID设置成0，那么配置的更改将被取消(但是ApplyConfChange必须通过某种方式调用，并且取消配置变更只有状态机能做，即使是健康检查也不行)3. Apply Snapshot (if any) and CommittedEntries to the state machine.If any committed Entry has Type EntryConfChange, call Node.ApplyConfChange()to apply it to the node. The configuration change may be cancelled at this pointby setting the NodeID field to zero before calling ApplyConfChange(but ApplyConfChange must be called one way or the other, and the decision to cancelmust be based solely on the state machine and not external information such asthe observed health of the node).# 4.调用 Node.Advance()标志下一个batch已经准备好发送。这在步骤1之后的任何时候都有可能完成，不过所有的更新必须在按照Ready返回的顺序执行。4. Call Node.Advance() to signal readiness for the next batch of updates.This may be done at any time after step 1, although all updates must be processedin the order they were returned by Ready.# 第二，持久化的实现需要保证所有的日志实体是可读取的的，比如提供的MemoryStorage，或者你可以自己实现Second, all persisted log entries must be made available via animplementation of the Storage interface. The provided MemoryStoragetype can be used for this (if you repopulate its state upon arestart), or you can supply your own disk-backed implementation.# 第三， 当你从其他节点中收到消息的时候，将消息传递给 Node.Step:Third, when you receive a message from another node, pass it to Node.Step: func recvRaftRPC(ctx context.Context, m raftpb.Message) &#123; n.Step(ctx, m) &#125;# 最后，你需要定时调用 Node.Tick()。Raft有两种超时: 心跳超时和选举超时。他们在raft包被抽象成同一个Finally, you need to call Node.Tick() at regular intervals (probablyvia a time.Ticker). Raft has two important timeouts: heartbeat and theelection timeout. However, internally to the raft package time isrepresented by an abstract \"tick\".# 综上，状态机的处理循环就像下面这样:The total state machine handling loop will look something like this: for &#123; select &#123; case &lt;-s.Ticker: n.Tick() case rd := &lt;-s.Node.Ready(): saveToStorage(rd.State, rd.Entries, rd.Snapshot) send(rd.Messages) if !raft.IsEmptySnap(rd.Snapshot) &#123; processSnapshot(rd.Snapshot) &#125; for _, entry := range rd.CommittedEntries &#123; process(entry) if entry.Type == raftpb.EntryConfChange &#123; var cc raftpb.ConfChange cc.Unmarshal(entry.Data) s.Node.ApplyConfChange(cc) &#125; &#125; s.Node.Advance() case &lt;-s.done: return &#125; &#125;# 要向状态机发起议案，需要将你的节点应用数据序列化成byte数组，然后调用n.Propose(ctx, data)To propose changes to the state machine from your node take your applicationdata, serialize it into a byte slice and call: n.Propose(ctx, data)# 如果完成提交，数据将变成具有EntryNormal类型的已提交数据。一个提议命令如果已经提交是没有过期时间的，你必须在超时之后重新发起If the proposal is committed, data will appear in committed entries with typeraftpb.EntryNormal. There is no guarantee that a proposed command will becommitted; you may have to re-propose after a timeout.# 添加或移除节点，构建配置然后调用ProposeConfChangeTo add or remove node in a cluster, build ConfChange struct 'cc' and call: n.ProposeConfChange(ctx, cc)# 在配置更改提交之后，一些有着EntryConfChange类型的Entries会被返回，解析后通过ApplyConfChange应用它们After config change is committed, some committed entry with typeraftpb.EntryConfChange will be returned. You must apply it to node through: var cc raftpb.ConfChange cc.Unmarshal(data) n.ApplyConfChange(cc)# 注意，节点ID必须总是唯一Note: An ID represents a unique node in a cluster for all time. Agiven ID MUST be used only once even if the old node has been removed.This means that for example IP addresses make poor node IDs since theymay be reused. Node IDs must be non-zero.# 实现笔记Implementation notes# 实现基本是跟着Raft thesis 同步更新的，但是还是与第4章节描述的有所差异。关键的差异是，保留在节点memberships一次改变时，我们的实现时在entry被应用的时候，而不是它被加到log中的时候(因此，entry在提交后还是原来的成员而不是新的)。这是为了安全性This implementation is up to date with the final Raft thesis(https://ramcloud.stanford.edu/~ongaro/thesis.pdf), although ourimplementation of the membership change protocol differs somewhat fromthat described in chapter 4. The key invariant that membership changeshappen one node at a time is preserved, but in our implementation themembership change takes effect when its entry is applied, not when itis added to the log (so the entry is committed under the oldmembership instead of the new). This is equivalent in terms of safety,since the old and new configurations are guaranteed to overlap.# 为了确保不会一次性提交两次成员变化，我们在leader节点没有提交完成的时候，不允许提起成员变化To ensure that we do not attempt to commit two membership changes atonce by matching log positions (which would be unsafe since theyshould have different quorum requirements), we simply disallow anyproposed membership change while any uncommitted change appears inthe leader's log.# 这里介绍了这样一个问题: 当只有两个节点的时候，如果一个成员在另一个节点收到配置变化提交之前死亡，那么集群将会完全失效，因此强烈建议构建三个以上节点的集群This approach introduces a problem when you try to remove a memberfrom a two-member cluster: If one of the members dies before theother one receives the commit of the confchange entry, then the membercannot be removed any more since the cluster cannot make progress.For this reason it is highly recommended to use three or more nodes inevery cluster.# 消息类型MessageTypePackage raft sends and receives message in Protocol Buffer format (definedin raftpb package). Each state (follower, candidate, leader) implements itsown 'step' method ('stepFollower', 'stepCandidate', 'stepLeader') whenadvancing with the given raftpb.Message. Each step is determined by itsraftpb.MessageType. Note that every step is checked by one common method'Step' that safety-checks the terms of node and incoming message to preventstale log entries: # MsgHup用于选举过程。如果在一个tickElection中，节点没有收到心跳，就发送MsgHup 给Step，并成为候选者 'MsgHup' is used for election. If a node is a follower or candidate, the 'tick' function in 'raft' struct is set as 'tickElection'. If a follower or candidate has not received any heartbeat before the election timeout, it passes 'MsgHup' to its Step method and becomes (or remains) a candidate to start a new election. # MsgBeat 是节点内部的心跳消息类型，由主节点定时向各follew发起 'MsgBeat' is an internal type that signals the leader to send a heartbeat of the 'MsgHeartbeat' type. If a node is a leader, the 'tick' function in the 'raft' struct is set as 'tickHeartbeat', and triggers the leader to send periodic 'MsgHeartbeat' messages to its followers. # MsgProp 发起提议，用来将议案转发给主节点。这里send方法用硬件状态的Term重写了 Message的Term以避免直接将本地的term附加给MsgProp。当MsgProp传递给主节点，主节 点立即将消息append到日志队列，然后调用bcastAppend将这些entried广播给各个节点。 如果发送给了候选者，会被候选者丢掉，当发给跟随者，跟随者将会通过send发放将消息存 入mailbox(消息)。消息存储的时候会带上发送者的ID然后通过raftHttp发送给leader。 'MsgProp' proposes to append data to its log entries. This is a special type to redirect proposals to leader. Therefore, send method overwrites raftpb.Message's term with its HardState's term to avoid attaching its local term to 'MsgProp'. When 'MsgProp' is passed to the leader's 'Step' method, the leader first calls the 'appendEntry' method to append entries to its log, and then calls 'bcastAppend' method to send those entries to its peers. When passed to candidate, 'MsgProp' is dropped. When passed to follower, 'MsgProp' is stored in follower's mailbox(msgs) by the send method. It is stored with sender's ID and later forwarded to leader by rafthttp package. # MsgApp 包含了要复制的日志，主节点bcastAppend的时候会通过sendAppend发送MsgApp 消息，意味着消息需要尽快发送出去。当MsgApp发送给候选者，候选者会重新变回跟随者，因为 这意味着这是合法leader发过来的消息，就不需要再选举了。候选者和跟随者会回 MsgAppResp消息 'MsgApp' contains log entries to replicate. A leader calls bcastAppend, which calls sendAppend, which sends soon-to-be-replicated logs in 'MsgApp' type. When 'MsgApp' is passed to candidate's Step method, candidate reverts back to follower, because it indicates that there is a valid leader sending 'MsgApp' messages. Candidate and follower respond to this message in 'MsgAppResp' type. # MsgAppResp，日志复制回复 'MsgAppResp' is response to log replication request('MsgApp'). When 'MsgApp' is passed to candidate or follower's Step method, it responds by calling 'handleAppendEntries' method, which sends 'MsgAppResp' to raft mailbox. # MsgVote 是用来请求选票的。当跟随者或者候选人发送MsgHup消息给它的Step方法之后， 节点会调用campaign方法参加竞选，使自己成为候选人。一旦campaign调用，节点及腰发 送MsgVote给集群的每个成员要求选票。当消息被传递给leader或者候选人的Step方法，并且 消息的term比他们自己term小，选举会被拒绝(MsgVoteResp回复附带拒绝标志)。如果 leader或者候选者收到的选举消息附带的Term更大，他们会转化成follower。当消息传递 给follower，只有当发送者当term和lastCommitted index大于等于接收节点的时候，才 会投票 'MsgVote' requests votes for election. When a node is a follower or candidate and 'MsgHup' is passed to its Step method, then the node calls 'campaign' method to campaign itself to become a leader. Once 'campaign' method is called, the node becomes candidate and sends 'MsgVote' to peers in cluster to request votes. When passed to leader or candidate's Step method and the message's Term is lower than leader's or candidate's, 'MsgVote' will be rejected ('MsgVoteResp' is returned with Reject true). If leader or candidate receives 'MsgVote' with higher term, it will revert back to follower. When 'MsgVote' is passed to follower, it votes for the sender only when sender's last term is greater than MsgVote's term or sender's last term is equal to MsgVote's term but sender's last committed index is greater than or equal to follower's. # 选票结果，候选人接收到后统计票数，超过半数则成为leader，broadcast广告给所有节点。 否则从新变成follower 'MsgVoteResp' contains responses from voting request. When 'MsgVoteResp' is passed to candidate, the candidate calculates how many votes it has won. If it's more than majority (quorum), it becomes leader and calls 'bcastAppend'. If candidate receives majority of votes of denials, it reverts back to follower. # MsgPreVote 和 MsgPreVoteResp 用于二阶段选举。当配置的PreVote是true的时 候，二阶段选举才会派上用场。并且节点不会增加term，除非pre-election已经告知了竞选 节点胜出。这样减少当分区节点重新加入时候的混乱。 'MsgPreVote' and 'MsgPreVoteResp' are used in an optional two-phase election protocol. When Config.PreVote is true, a pre-election is carried out first (using the same rules as a regular election), and no node increases its term number unless the pre-election indicates that the campaigining node would win. This minimizes disruption when a partitioned node rejoins the cluster. # MsgSnap 要求加载消息。当一个节点刚成为leader的时候，或者leader收到MsgProp的 时候，它调用bcastAppend方法给个节点同步消息的时候，如果获取不到term或者 entries，leader就会发送MsgSnap获取快照。 'MsgSnap' requests to install a snapshot message. When a node has just become a leader or the leader receives 'MsgProp' message, it calls 'bcastAppend' method, which then calls 'sendAppend' method to each follower. In 'sendAppend', if a leader fails to get term or entries, the leader requests snapshot by sending 'MsgSnap' type message. # MsgSnapStatus 告知快照结果。当follower拒绝返回，就意味着主节点与之网络连接 失败，主节点就会考虑对该节点进行网络探测。当返回了，意味着foller接收了快照并恢复了 日志复制 'MsgSnapStatus' tells the result of snapshot install message. When a follower rejected 'MsgSnap', it indicates the snapshot request with 'MsgSnap' had failed from network issues which causes the network layer to fail to send out snapshots to its followers. Then leader considers follower's progress as probe. When 'MsgSnap' were not rejected, it indicates that the snapshot succeeded and the leader sets follower's progress to probe and resumes its log replication. # MsgHeartbeat leader给follwer发心跳。当心跳发送给候选人，如果term高于候选 人，候选人重新成为follower并更新提交索引。如果发送给follower，候选人更新 leaderId 'MsgHeartbeat' sends heartbeat from leader. When 'MsgHeartbeat' is passed to candidate and message's term is higher than candidate's, the candidate reverts back to follower and updates its committed index from the one in this heartbeat. And it sends the message to its mailbox. When 'MsgHeartbeat' is passed to follower's Step method and message's term is higher than follower's, the follower updates its leaderID with the ID from the message. # MsgHeartbeatResp， 心跳返回，附带follower的日志id，点那个日志id比leader大的 时候，发送append 'MsgHeartbeatResp' is a response to 'MsgHeartbeat'. When 'MsgHeartbeatResp' is passed to leader's Step method, the leader knows which follower responded. And only when the leader's last committed index is greater than follower's Match index, the leader runs 'sendAppend` method. # MsgUnreachable 表示消息发送失败。当主节点收到该消息的时候，主节点会发现发送该消 息的节点不可达，基本意味着MsgApp消息丢失。 'MsgUnreachable' tells that request(message) wasn't delivered. When 'MsgUnreachable' is passed to leader's Step method, the leader discovers that the follower that sent this 'MsgUnreachable' is not reachable, often indicating 'MsgApp' is lost. When follower's progress state is replicate, the leader sets it back to probe.*/package raft","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"},{"name":"算法","slug":"算法","permalink":"http://ipiao.top/tags/算法/"},{"name":"分布式","slug":"分布式","permalink":"http://ipiao.top/tags/分布式/"}]},{"title":"Go Plugin动态加载库","date":"2020-03-11T10:25:00.000Z","path":"2020/03/11/Go-Plugin动态加载库/","text":"利用Go plugin实现动态加载库文件 调用文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475 package mainimport ( \"fmt\" \"os\" \"plugin\" \"strings\" \"sync\" \"time\")var ( fn func() // plugin 动态加载的函数 fnLock sync.RWMutex)func main() &#123; tick := time.NewTicker(time.Second) inputCh := readInput() for &#123; select &#123; case &lt;-tick.C: execFn() case file := &lt;-inputCh: fmt.Printf(\"loading plugin file : %s\\n\", file) load(file) &#125; &#125;&#125;func readInput() &lt;-chan string &#123; ch := make(chan string, 1) go func() &#123; b := make([]byte, 16) for &#123; n, err := os.Stdin.Read(b) if err != nil &#123; // &#125; if n &gt; 0 &#123; ch &lt;- string(b[:n]) &#125; &#125; &#125;() return ch&#125;func load(file string) &#123; file = strings.TrimSpace(file) p, err := plugin.Open(\"./myplugin/\" + file) if err != nil &#123; fmt.Printf(\"Open plugin error: %v\\n\", err) return &#125; sb, err := p.Lookup(\"Print\") if err != nil &#123; fmt.Printf(\"plugin lookup failed, error: %v\\n\", err) return &#125; nfn, _ := sb.(func()) fnLock.Lock() fn = nfn fnLock.Unlock()&#125;func execFn() &#123; if fn != nil &#123; fnLock.RLock() defer fnLock.RUnlock() fn() &#125;&#125; 上面的代码模拟了一个简单的服务场景。 监听用户输入，模拟库文件的更新（库文件不能同名，否则会当作同一个文件） 在库文件加载进来后实现库函数的调用 库文件 12345678 package mainimport \"fmt\"func Print() &#123; fmt.Println(\"这是p1加载的plugin“） // fmt.Println(\"这是p2加载的plugin\")&#125; 编译成库文件 12 go build -buildmode=plugin -o print.so p1.go# go build -buildmode=plugin -o print2.so p2.go 终端输入编译后的文件路径，获取终端的输出","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"mysql并发调试","date":"2019-10-24T03:00:00.000Z","path":"2019/10/24/mysql并发调试命名/","text":"常用命令列举 主要是 INFORMATION_SCHEMA 库里的表 12345678910111213141516171819202122232425262728293031 -- 包含事务正在等待的锁的信息SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;-- 包含当前运行的所有事务的列表SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;-- 包含事务持有的当前锁的相关信息以及每个事务等待的锁的信息SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;-- 阻塞的事务列表SELECT INNODB_LOCKS.* FROM INFORMATION_SCHEMA.INNODB_LOCKS JOIN INFORMATION_SCHEMA.INNODB_LOCK_WAITS ON (INFORMATION_SCHEMA.INNODB_LOCKS.LOCK_TRX_ID = INFORMATION_SCHEMA.INNODB_LOCK_WAITS.BLOCKING_TRX_ID)-- 特定表上的锁的列表SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS WHERE LOCK_TABLE = 'db_name.tables_name';-- 等待锁的事务列表SELECT TRX_ID, TRX_REQUESTED_LOCK_ID, TRX_MYSQL_THREAD_ID, TRX_QUERY FROM INFORMATION_SCHEMA.INNODB_TRX WHERE TRX_STATE = 'LOCK WAIT';-- INNODB 监控器show engine innodb status;show full processlist ;kill 600678;show status like 'innodb_row_lock%'; -- 行锁show status like '%lock%'; show OPEN TABLES where In_use &gt; 0; PERFORMANCE_SCHEMA 中的表(*_INSTANCES) 所有的*_INSTANCES表都包含 NAME和OBJECT_INSTANCE_BEGIN字段，这两个字段分别代表实例的名称和对象检测时的内存地址 COND_INSTANCES: 表包含等待条件列表，这些条件是在服务器启动后生成的。条件是指使一个线程等待其他线程的方式方法。 FILE_INSTANCES: 表包含性能架构可见的文件列表。当服务器首次打开文件的时候就将文件名插入该表，并且在文件从磁盘删除之前都会保存在该表之中。目前（…）打开文件会有一个正的 OPEN_COUNT计数。Number字段保存当前使用该文件的文件句柄数量。 MUTEX_INSTANCES: 表包含性能架构可见的互斥列表。互斥记录中 LOCKED_BY_THREAD_IS 的值为 NOT NULL 部分是当前锁定的互斥。 RWLOCK_INSTANCE: 表包含所有读/写锁实例的列表。WRITE_LOCKED_BY_THREAD_IS 字段代表持有锁的线程ID。READ_LOCKED_BYCOUNT字段代表当前在实例上获取了多少读锁。 EVENTS_WAITS_*： 系列表包含每个线程等待的事件的信息。 *SUMMARY*: 表包含被终止事件的聚合信息。 其他命令 1234 -- 查看变量show variables like &apos;%xxx%&apos;;-- 查系统变量select @@xxx;","tags":[{"name":"mysql","slug":"mysql","permalink":"http://ipiao.top/tags/mysql/"}]},{"title":"TCP Delayed Ack(Ack确认延迟) && Nagle Algorithm(纳格算法)","date":"2019-09-11T06:51:00.000Z","path":"2019/09/11/TCP-Delayed-Ack-Ack确认延迟-Nagle-Algorithm-纳格算法/","text":"[原文连接: https://www.jianshu.com/p/bc3c1d6dafe8?from=singlemessage] 如果一个 TCP 连接的一端启用了 Nagle‘s Algorithm，而另一端启用了 TCP DelayedAck，而发送的数据包又比较小，则可能会出现这样的情况：发送端在等 待接收端对上一个packet 的 Ack 才发送当前的 packet，而接收端则正好延迟了 此 Ack 的发送，那么这个正要被发送的 packet 就会同样被延迟。当然 Delayed Ack 是有个超时机制的，而默认的超时正好就是40ms。 1.Delayed Ack tcp协议规定在接受到数据段时需要向对方发送一个确认,但如果只是单纯的发送一个确认,代价会比较高(20字节的ip首部,20字节的tcp首部),最好能附带响应数据一起发送给对 方.所以tcp在何时发送ack给对方有以下规定: 1) 当有响应数据要发送时,ack会随响数据立即发送给对方.2) 如果没有响应数据,ack的发 送将会有一个延迟,以等待看是否有响应数据可以一起发送 ,这称是”Delayed Ack”.但这个延迟最多不会超过500ms,一般为200ms.如果在200ms内有数据要发送,那么ack会随数据一起立即发送给对方.注意这里的延迟200ms,不是指的从接受到对方数据到发送ack的最长等待时间差.而是指的内核启动的一个定时器,它每隔200ms就查看下是否有ack要发送.例如:假设定时器在0ms时启动,对方的数据段在185ms时到达,那么ack最迟会在200ms时发送,而不是385ms时发送. 3) 如果在等待发送ack期间,对方的第二个数据段又到达了,这时要立即发送ack.但是如果对方的三个数据段相继 到达,那么第二个数据段到达时ack立即发送,但第三个数据段到达时是否立即发送,则取决于上面两条. 2.Nagle Algorithm 当tcp协议用来传输小的数据段时代码是很高的,并且如果传输是在广域网上,那可能就会引起网络拥塞.Nagle算法就是用来解决这个问题.该算法要求一个TCP连接上最多只能有一个未被确认(未收到Ack确认)的未完成的小分组，在该分组的确认到达之前不能发送其他的小分组。相反TCP收集这些少量的分组，并在确认到来时以一 个分组的方式发出去.Host Requirements RFC声明TCP必须实现Nagle算法，但必须为应用提供一种方法来关闭该算法在某个连接上执行。 纳格算法是合并(coalescing)一定数量的输出资料后一次送出。特别的是，只要有已送出的封包尚未确认，传送者会持续缓冲封包，直到累积一定数量的资料才送出。 算法如下如下： 12345678 if 有新资料要传送 if 讯窗大小 &gt;= MSS and 可传送的资料 &gt;= MSS 立刻传送完整MSS大小的segment else if 管线中有尚未确认的资料 在下一个确认(ACK)封包收到前，将资料排进缓冲区伫列 else ( MSS=最大segment大小) 为什么要同时介绍这两个知识呢？因为这两个技术同时使用的话会出现问题，下面来看一下问题的出现场景:A 和B进行数据传输: A运行Nagle算法， B运行delayed ACK算法 A-&gt;B 发一个packet(数据包), B不回应，delay ACK A-&gt; 再发一个packet(数据包) B收到第二个packet(数据包)，这时候会回应第一个packet(数据包)，即第一个ACK 假设这时候A里的数据已经发送完 此时问题就来了，因为A没有收到第二个packet的ACK确认，同时数据当然我们从上面可以看到这种等待机制还是有副作用的，那就是需要等待：一项数据表明：在以太网上,传输100000字节仅需1ms,但由于delayed ack和nagle的作用却要花费201ms,这显然对程序的效率产生了很大影响.TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。（一个连接会设置MSS参数，因此，TCP/IP希望每次都能够以MSS尺寸的数据块来发送数据）。Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。Nagle算法的基本定义是任意时刻，最多只能有一个未被确认的小段。所谓“小段”，指的是小于MSS尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。 举个例子，比如之前的blog中的实验，一开始client端调用socket的write操作将一个int型数据(称为A块)写入到网络中，由于此时连接是空闲的（也就是说还没有未被确认的小段），因此这个int型数据会被马上发送到server端，接着，client端又调用write操作写入‘/r/n’（简称B块），这个时候，A块的ACK没有返回，所以可以认为已经存在了一个未被确认的小段，所以B块没有立即被发送，一直等待A块的ACK收到（大概40ms之后），B块才被发送。整个过程如图所示： 这里还隐藏了一个问题，就是A块数据的ACK为什么40ms之后才收到？这是因为TCP/IP中不仅仅有nagle算法，还有一个ACK延迟机制。当Server端收到数据之后，它并不会马上向client端发送ACK，而是会将ACK的发送延迟一段时间（假设为t），它希望在t时间内server端会向client端发送应答数据，这样ACK就能够和应答数据一起发送，就像是应答数据捎带着ACK过去。在我之前的时间中，t大概就是40ms。这就解释了为什么’/r/n’(B块)总是在A块之后40ms才发出。 如果你觉着nagle算法太捣乱了，那么可以通过设置TCP_NODELAY将其禁用。当然，更合理的方案还是应该使用一次大数据的写操作，而不是多次小数据的写操作。","tags":[{"name":"tcp","slug":"tcp","permalink":"http://ipiao.top/tags/tcp/"}]},{"title":"Go语言TCP网络编程","date":"2019-09-11T06:41:00.000Z","path":"2019/09/11/Go语言TCP网络编程/","text":"[原文链接：https://blog.csdn.net/hacker00011000/article/details/53910367] 一、序言 Golang的主要 设计目标之一就是面向大规模后端服务程序，网络通信这块是服务端 程序必不可少也是至关重要的一部分。在日常应用中，我们也可以看到Go中的net以及其subdirectories下的包均是“高频+刚需”，而TCP socket则是网络编程的主流，即便您没有直接使用到net中有关TCP Socket方面的接口，但net/http总是用到了吧，http底层依旧是用tcp socket实现的 网络编程方面，我们最常用的就是tcp socket编程了，在posix标准出来后，socket在各大主流OS平台上都得到了很好的支持。关于tcp programming，最好的资料莫过于W. Richard Stevens 的网络编程圣经《UNIX网络 编程 卷1：套接字联网API》 了，书中关于tcp socket接口的各种使用、行为模式、异常处理讲解的十分细致。Go是自带runtime的跨平台编程语言，Go中暴露给语言使用者的tcp socket api是建立OS原生tcp socket接口之上的。由于Go runtime调度的需要，golang tcp socket接口在行为特点与异常处理方面与OS原生接口有着一些差别。这篇博文的目标就是整理出关于Go tcp socket在各个场景下的使用方法、行为特点以及注意事项 二、模型 从tcp socket诞生后，网络编程架构模型也几经演化，大致是：“每进程一个连接” –&gt; “每线程一个连接” –&gt; “Non-Block + I/O多路复用(linux epoll/windows iocp/freebsd darwin kqueue/solaris Event Port)”。伴随着模型的演化，服务程序愈加强大，可以支持更多的连接，获得更好的处理性能 目前主流web server一般均采用的都是”Non-Block + I/O多路复用”（有的也结合了多线程、多进程）。不过I/O多路复用也给使用者带来了不小的复杂度，以至于后续出现了许多高性能的I/O多路复用框架， 比如libevent、libev、libuv等，以帮助开发者简化开发复杂性，降低心智负担。不过Go的设计者似乎认为I/O多路复用的这种通过回调机制割裂控制流 的方式依旧复杂，且有悖于“一般逻辑”设计，为此Go语言将该“复杂性”隐藏在Runtime中了：Go开发者无需关注socket是否是 non-block的，也无需亲自注册文件描述符的回调，只需在每个连接对应的goroutine中以“block I/O”的方式对待socket处理即可，这可以说大大降低了开发人员的心智负担。一个典型的Go server端程序大致如下 123456789101112131415161718192021222324252627282930 //go-tcpsock/server.gofunc HandleConn(conn net.Conn) &#123; defer conn.Close() for &#123; // read from the connection // ... ... // write to the connection //... ... &#125;&#125;func main() &#123; listen, err := net.Listen(\"tcp\", \":8888\") if err != nil &#123; fmt.Println(\"listen error: \", err) return &#125; for &#123; conn, err := listen.Accept() if err != nil &#123; fmt.Println(\"accept error: \", err) break &#125; // start a new goroutine to handle the new connection go HandleConn(conn) &#125;&#125; 用户层眼中看到的goroutine中的“block socket”，实际上是通过Go runtime中的netpoller通过Non-block socket + I/O多路复用机制“模拟”出来的，真实的underlying socket实际上是non-block的，只是runtime拦截了底层socket系统调用的错误码，并通过netpoller和goroutine 调度让goroutine“阻塞”在用户层得到的Socket fd上。比如：当用户层针对某个socket fd发起read操作时，如果该socket fd中尚无数据，那么runtime会将该socket fd加入到netpoller中监听，同时对应的goroutine被挂起，直到runtime收到socket fd 数据ready的通知，runtime才会重新唤醒等待在该socket fd上准备read的那个Goroutine。而这个过程从Goroutine的视角来看，就像是read操作一直block在那个socket fd上似的。具体实现细节在后续场景中会有补充描述 三、TCP连接的建立 众所周知，TCP Socket的连接的建立需要经历客户端和服务端的三次握手的过程。连接建立过程中，服务端是一个标准的Listen + Accept的结构(可参考上面的代码)，而在客户端Go语言使用net.Dial()或net.DialTimeout()进行连接建立 阻塞Dial： 12345 conn, err := net.Dial(\"tcp\", \"www.baidu.com:80\")if err != nil &#123; //handle error&#125;//read or write on conn 超时机制的Dial： 12345 conn, err := net.DialTimeout(\"tcp\", \"www.baidu.com:80\", 2*time.Second)if err != nil &#123; //handle error&#125;//read or write on conn 对于客户端而言，连接的建立会遇到如下几种情形： 1、网络不可达或对方服务未启动如果传给Dial的Addr是可以立即判断出网络不可达，或者Addr中端口对应的服务没有启动，端口未被监听，Dial会几乎立即返回错误，比如： 123456789101112 //go-tcpsock/conn_establish/client1.go... ...func main() &#123; log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil &#123; log.Println(\"dial error:\", err) return &#125; defer conn.Close() log.Println(\"dial ok\")&#125; 如果本机8888端口未有服务程序监听，那么执行上面程序，Dial会很快返回错误： 123 $go run client1.go2015/11/16 14:37:41 begin dial...2015/11/16 14:37:41 dial error: dial tcp :8888: getsockopt: connection refused 2、对方服务的listen backlog满还有一种场景就是对方服务器很忙，瞬间有大量client端连接尝试向server建立，server端的listen backlog队列满，server accept不及时((即便不accept，那么在backlog数量范畴里面，connect都会是成功的，因为new conn已经加入到server side的listen queue中了，accept只是从queue中取出一个conn而已)，这将导致client端Dial阻塞。我们还是通过例子感受Dial的行为特点：服务端代码： 12345678910111213141516171819202122 //go-tcpsock/conn_establish/server2.go... ...func main() &#123; l, err := net.Listen(\"tcp\", \":8888\") if err != nil &#123; log.Println(\"error listen:\", err) return &#125; defer l.Close() log.Println(\"listen ok\") var i int for &#123; time.Sleep(time.Second * 10) if _, err := l.Accept(); err != nil &#123; log.Println(\"accept error:\", err) break &#125; i++ log.Printf(\"%d: accept a new connection\\n\", i) &#125;&#125; 客户端代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 //go-tcpsock/conn_establish/client2.go... ...func establishConn(i int) net.Conn &#123; conn, err := net.Dial(\"tcp\", \":8888\") if err != nil &#123; log.Printf(\"%d: dial error: %s\", i, err) return nil &#125; log.Println(i, \":connect to server ok\") return conn&#125;func main() &#123; var sl []net.Conn for i := 1; i &lt; 1000; i++ &#123; conn := establishConn(i) if conn != nil &#123; sl = append(sl, conn) &#125; &#125; time.Sleep(time.Second * 10000)&#125;``` 从程序可以看出，服务端在listen成功后，每隔10s钟accept一次。客户端则是串行的尝试建立连接。这两个程序在Darwin下的执行 结果：``` sh$go run server2.go2015/11/16 21:55:41 listen ok2015/11/16 21:55:51 1: accept a new connection2015/11/16 21:56:01 2: accept a new connection... ...$go run client2.go2015/11/16 21:55:44 1 :connect to server ok2015/11/16 21:55:44 2 :connect to server ok2015/11/16 21:55:44 3 :connect to server ok... ...2015/11/16 21:55:44 126 :connect to server ok2015/11/16 21:55:44 127 :connect to server ok2015/11/16 21:55:44 128 :connect to server ok2015/11/16 21:55:52 129 :connect to server ok2015/11/16 21:56:03 130 :connect to server ok2015/11/16 21:56:14 131 :connect to server ok... ... 可以看出Client初始时成功地一次性建立了128个连接，然后后续每阻塞近10s才能成功建立一条连接。也就是说在server端 backlog满时(未及时accept)，客户端将阻塞在Dial上，直到server端进行一次accept。至于为什么是128，这与darwin 下的默认设置有关：如果我在ubuntu 14.04上运行上述server程序，我们的client端初始可以成功建立499条连接。 如果server一直不accept，client端会一直阻塞么？我们去掉accept后的结果是：在Darwin下，client端会阻塞大 约1分多钟才会返回timeout：而如果server运行在ubuntu 14.04上，client似乎一直阻塞，我等了10多分钟依旧没有返回。 阻塞与否看来与server端的网络实现和设置有关 3、网络延迟较大，Dial阻塞并超时如果网络延迟较大，TCP握手过程将更加艰难坎坷（各种丢包），时间消耗的自然也会更长。Dial这时会阻塞，如果长时间依旧无法建立连接，则Dial也会返回“ getsockopt: operation timed out”错误 在连接建立阶段，多数情况下，Dial是可以满足需求的，即便阻塞一小会儿。但对于某些程序而言，需要有严格的连接时间限定，如果一定时间内没能成功建立连接，程序可能会需要执行一段“异常”处理逻辑，为此我们就需要DialTimeout了。下面的例子将Dial的最长阻塞时间限制在2s内，超出这个时长，Dial将返回timeout error： 123456789101112 //go-tcpsock/conn_establish/client3.go... ...func main() &#123; log.Println(\"begin dial...\") conn, err := net.DialTimeout(\"tcp\", \"104.236.176.96:80\", 2*time.Second) if err != nil &#123; log.Println(\"dial error:\", err) return &#125; defer conn.Close() log.Println(\"dial ok\")&#125; 执行结果如下，需要模拟一个网络延迟大的环境 123 $go run client3.go2015/11/17 09:28:34 begin dial...2015/11/17 09:28:36 dial error: dial tcp 104.236.176.96:80: i/o timeout 四、Socket读写 连接建立起来后，我们就要在conn上进行读写，以完成业务逻辑。前面说过Go runtime隐藏了I/O多路复用的复杂性。语言使用者只需采用goroutine+Block I/O的模式即可满足大部分场景需求。Dial成功后，方法返回一个net.Conn接口类型变量值，这个接口变量的动态类型为一个*TCPConn： 1234 //$GOROOT/src/net/tcpsock_posix.gotype TCPConn struct &#123; conn&#125; TCPConn内嵌了一个unexported类型：conn，因此TCPConn”继承”了conn的Read和Write方法，后续通过Dial返回值调用的Write和Read方法均是net.conn的方法： 1234567891011121314151617181920212223242526272829303132 //$GOROOT/src/net/net.gotype conn struct &#123; fd *netFD&#125;func (c *conn) ok() bool &#123; return c != nil &amp;&amp; c.fd != nil &#125;// Implementation of the Conn interface.// Read implements the Conn Read method.func (c *conn) Read(b []byte) (int, error) &#123; if !c.ok() &#123; return 0, syscall.EINVAL &#125; n, err := c.fd.Read(b) if err != nil &amp;&amp; err != io.EOF &#123; err = &amp;OpError&#123;Op: \"read\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err&#125; &#125; return n, err&#125;// Write implements the Conn Write method.func (c *conn) Write(b []byte) (int, error) &#123; if !c.ok() &#123; return 0, syscall.EINVAL &#125; n, err := c.fd.Write(b) if err != nil &#123; err = &amp;OpError&#123;Op: \"write\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err&#125; &#125; return n, err&#125; 1、conn.Read的行为特点 1.1、Socket中无数据连接建立后，如果对方未发送数据到socket，接收方(Server)会阻塞在Read操作上，这和前面提到的“模型”原理是一致的。执行该Read操作的goroutine也会被挂起。runtime会监视该socket，直到其有数据才会重新调度该socket对应的Goroutine完成read。由于篇幅原因，这里就不列代码了，例子对应的代码文件：go-tcpsock/read_write下的client1.go和server1.go。 1.2、Socket中有部分数据如果socket中有部分数据，且长度小于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回，而不是等待所有期望数据全部读取后再返回。 1.3、Socket中有足够数据如果socket中有数据，且长度大于等于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回。这个情景是最符合我们对Read的期待的了：Read将用Socket中的数据将我们传入的slice填满后返回：n = 10, err = nil 1.4、Socket关闭如果client端主动关闭了socket，那么Server的Read将会读到什么呢？这里分为“有数据关闭”和“无数据关闭”。 有数据关闭是指在client关闭时，socket中还有server端未读取的数据。当client端close socket退出后，server依旧没有开始Read，10s后第一次Read成功读出了所有的数据，当第二次Read时，由于client端 socket关闭，Read返回EOF error 无数据关闭情形下的结果，那就是Read直接返回EOF error 1.5、读取操作超时有些场合对Read的阻塞时间有严格限制，在这种情况下，Read的行为到底是什么样的呢？在返回超时错误时，是否也同时Read了一部分数据了呢？不会出现“读出部分数据且返回超时错误”的情况 2、conn.Write的行为特点 2.1、成功写前面例子着重于Read，client端在Write时并未判断Write的返回值。所谓“成功写”指的就是Write调用返回的n与预期要写入的数据长度相等，且error = nil。这是我们在调用Write时遇到的最常见的情形，这里不再举例了 2.2、写阻塞TCP连接通信两端的OS都会为该连接保留数据缓冲，一端调用Write后，实际上数据是写入到OS的协议栈的数据缓冲的。TCP是全双工通信，因此每个方向都有独立的数据缓冲。当发送方将对方的接收缓冲区以及自身的发送缓冲区写满后，Write就会阻塞 2.3、写入部分数据Write操作存在写入部分数据的情况。没有按照预期的写入所有数据。这时候循环写入便是 综上例子，虽然Go给我们提供了阻塞I/O的便利，但在调用Read和Write时依旧要综合需要方法返回的n和err的结果，以做出正确处理。net.conn实现了io.Reader和io.Writer接口，因此可以试用一些wrapper包进行socket读写，比如bufio包下面的Writer和Reader、io/ioutil下的函数等 五、Goroutine safe 基于goroutine的网络架构模型，存在在不同goroutine间共享conn的情况，那么conn的读写是否是goroutine safe的呢？在深入这个问题之前，我们先从应用意义上来看read操作和write操作的goroutine-safe必要性。 对于read操作而言，由于TCP是面向字节流，conn.Read无法正确区分数据的业务边界，因此多个goroutine对同一个conn进行read的意义不大，goroutine读到不完整的业务包反倒是增加了业务处理的难度。对与Write操作而言，倒是有多个goroutine并发写的情况。 每次Write操作都是受lock保护，直到此次数据全部write完。因此在应用层面，要想保证多个goroutine在一个conn上write操作的Safe，需要一次write完整写入一个“业务包”；一旦将业务包的写入拆分为多次write，那就无法保证某个Goroutine的某“业务包”数据在conn发送的连续性。 同时也可以看出即便是Read操作，也是lock保护的。多个Goroutine对同一conn的并发读不会出现读出内容重叠的情况，但内容断点是依 runtime调度来随机确定的。存在一个业务包数据，1/3内容被goroutine-1读走，另外2/3被另外一个goroutine-2读 走的情况。比如一个完整包：world，当goroutine的read slice size &lt; 5时，存在可能：一个goroutine读到 “worl”,另外一个goroutine读出”d”。 六、Socket属性 原生Socket API提供了丰富的sockopt设置接口，但Golang有自己的网络架构模型，golang提供的socket options接口也是基于上述模型的必要的属性设置。包括SetKeepAliveSetKeepAlivePeriodSetLingerSetNoDelay （默认no delay）SetWriteBufferSetReadBuffer 不过上面的Method是TCPConn的，而不是Conn的，要使用上面的Method的，需要type assertion： 123456 tcpConn, ok := conn.(*TCPConn)if !ok &#123; //error handle&#125;tcpConn.SetNoDelay(true) 对于listener socket, golang默认采用了 SO_REUSEADDR，这样当你重启 listener程序时，不会因为address in use的错误而启动失败。而listen backlog的默认值是通过获取系统的设置值得到的。不同系统不同：mac 128, linux 512等 七、关闭连接和前面的方法相比，关闭连接算是最简单的操作了。由于socket是全双工的，client和server端在己方已关闭的socket和对方关闭的socket上操作的结果有不同。看下面例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 //go-tcpsock/conn_close/client1.go... ...func main() &#123; log.Println(\"begin dial...\") conn, err := net.Dial(\"tcp\", \":8888\") if err != nil &#123; log.Println(\"dial error:\", err) return &#125; conn.Close() log.Println(\"close ok\") var buf = make([]byte, 32) n, err := conn.Read(buf) if err != nil &#123; log.Println(\"read error:\", err) &#125; else &#123; log.Printf(\"read % bytes, content is %s\\n\", n, string(buf[:n])) &#125; n, err = conn.Write(buf) if err != nil &#123; log.Println(\"write error:\", err) &#125; else &#123; log.Printf(\"write % bytes, content is %s\\n\", n, string(buf[:n])) &#125; time.Sleep(time.Second * 1000)&#125;//go-tcpsock/conn_close/server1.go... ...func handleConn(c net.Conn) &#123; defer c.Close() // read from the connection var buf = make([]byte, 10) log.Println(\"start to read from conn\") n, err := c.Read(buf) if err != nil &#123; log.Println(\"conn read error:\", err) &#125; else &#123; log.Printf(\"read %d bytes, content is %s\\n\", n, string(buf[:n])) &#125; n, err = c.Write(buf) if err != nil &#123; log.Println(\"conn write error:\", err) &#125; else &#123; log.Printf(\"write %d bytes, content is %s\\n\", n, string(buf[:n])) &#125;&#125;... ... 执行结果如下 1234567891011 $go run server1.go2015/11/17 17:00:51 accept a new connection2015/11/17 17:00:51 start to read from conn2015/11/17 17:00:51 conn read error: EOF2015/11/17 17:00:51 write 10 bytes, content is$go run client1.go2015/11/17 17:00:51 begin dial...2015/11/17 17:00:51 close ok2015/11/17 17:00:51 read error: read tcp 127.0.0.1:64195-&gt;127.0.0.1:8888: use of closed network connection2015/11/17 17:00:51 write error: write tcp 127.0.0.1:64195-&gt;127.0.0.1:8888: use of closed network connection 从client的结果来看，在己方已经关闭的socket上再进行read和write操作，会得到”use of closed network connection” error； 从server的执行结果来看，在对方关闭的socket上执行read操作会得到EOF error，但write操作会成功，因为数据会成功写入己方的内核socket缓冲区中，即便最终发不到对方socket缓冲区了，因为己方socket并未关闭。因此当发现对方socket关闭后，己方应该正确合理处理自己的socket，再继续write已经无任何意义了 八、小结 本文比较基础，但却很重要，毕竟golang是面向大规模服务后端的，对通信环节的细节的深入理解会大有裨益。另外Go的goroutine+阻塞通信的网络通信模型降低了开发者心智负担，简化了通信的复杂性，这点尤为重要","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"},{"name":"tcp","slug":"tcp","permalink":"http://ipiao.top/tags/tcp/"}]},{"title":"redis_其他","date":"2019-07-23T02:21:00.000Z","path":"2019/07/23/redis-其他/","text":"命令参考 http://redisdoc.com/index.html redis的一些技术点 ae事件模型 Redis AE异步事件库实例分析 Redis的事件循环与定时器模型 anet网络连接 结合redis设计与实现的redis源码学习-15-TCP网络连接（anet.c） bio redis BIO详解 Redis源码学习——BIO debug redis debug命令详解 geo geohash hyperloglog Redis 基数统计：HyperLogLog 小内存大用处 latency 聊聊redis的slowlog与latency monitor lazyfree Redis4.0新特性(三)-Lazy Free listpack 5.0新功能 zipmap Redis zipmap module 在Redis modules的实现自己的数据类型 networking Redis 源码阅读 ——— 网络模块 notify redis源码–notify quicklist Redis—quickList(快速列表) rax Redis 知识梳理 [ 基数树 ] rio Redis 之BIO与RIO sparkline redis学习笔记（8）—微线图sparkline","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"读<<Redis设计与实现>>与redis(5.0)源码__rdb","date":"2019-07-12T08:54:00.000Z","path":"2019/07/12/读-Redis设计与实现-与redis-5-0-源码-rdb/","text":"db 12345678910 typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB */ dict *expires; /* Timeout of keys with a timeout set */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */&#125; redisDb; save 书上说save的时候过期键不保留,load的时候保留.但是5.0代码中,情况相反.可能是saveInfo的关系.即使是定时任务,因为在redis的过期处理规则可能会有部分过期键没有删除掉(serverCron-&gt;databasesCron-&gt;activeExpireCycle),所以这个不保留不是绝对的 rdbSave-&gt;rdbSaveRio REDIS|db_version(4)|saveInfo|database|EOF|check_sum 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145 int rdbSaveRio(rio *rdb, int *error, int flags, rdbSaveInfo *rsi) &#123; dictIterator *di = NULL; dictEntry *de; char magic[10]; int j; uint64_t cksum; size_t processed = 0; if (server.rdb_checksum) // 校验函数 rdb-&gt;update_cksum = rioGenericUpdateChecksum; snprintf(magic,sizeof(magic),\"REDIS%04d\",RDB_VERSION); // 从这里开始,redis+4个字节的版本号 if (rdbWriteRaw(rdb,magic,9) == -1) goto werr; // 写入saveInfo,type是 RDB_OPCODE_AUX if (rdbSaveInfoAuxFields(rdb,flags,rsi) == -1) goto werr; for (j = 0; j &lt; server.dbnum; j++) &#123; redisDb *db = server.db+j; dict *d = db-&gt;dict; if (dictSize(d) == 0) continue; di = dictGetSafeIterator(d); /* Write the SELECT DB opcode */ // 写入SELECTDB = 254 if (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == -1) goto werr; // 调用的是写入长度,其实是写入数字 if (rdbSaveLen(rdb,j) == -1) goto werr; /* Write the RESIZE DB opcode. We trim the size to UINT32_MAX, which * is currently the largest type we are able to represent in RDB sizes. * However this does not limit the actual size of the DB to load since * these sizes are just hints to resize the hash tables. */ uint64_t db_size, expires_size; db_size = dictSize(db-&gt;dict); expires_size = dictSize(db-&gt;expires); // 写入db的size,RDB_OPCODE_RESIZEDB = 251 if (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == -1) goto werr; if (rdbSaveLen(rdb,db_size) == -1) goto werr; // 跟着过期字典的大小 if (rdbSaveLen(rdb,expires_size) == -1) goto werr; /* Iterate this DB writing every entry */ while((de = dictNext(di)) != NULL) &#123; sds keystr = dictGetKey(de); robj key, *o = dictGetVal(de); long long expire; initStaticStringObject(key,keystr); expire = getExpire(db,&amp;key); // key,value保存 if (rdbSaveKeyValuePair(rdb,&amp;key,o,expire) == -1) goto werr; /* When this RDB is produced as part of an AOF rewrite, move * accumulated diff from parent to child while rewriting in * order to have a smaller final write. */ // 这个应该是AOF重写中被rdb阻塞了而造成延迟 if (flags &amp; RDB_SAVE_AOF_PREAMBLE &amp;&amp; rdb-&gt;processed_bytes &gt; processed+AOF_READ_DIFF_INTERVAL_BYTES) &#123; processed = rdb-&gt;processed_bytes; aofReadDiffFromParent(); &#125; &#125; dictReleaseIterator(di); di = NULL; /* So that we don't release it again on error. */ &#125; /* If we are storing the replication information on disk, persist * the script cache as well: on successful PSYNC after a restart, we need * to be able to process any EVALSHA inside the replication backlog the * master will send us. */ if (rsi &amp;&amp; dictSize(server.lua_scripts)) &#123; di = dictGetIterator(server.lua_scripts); while((de = dictNext(di)) != NULL) &#123; robj *body = dictGetVal(de); if (rdbSaveAuxField(rdb,\"lua\",3,body-&gt;ptr,sdslen(body-&gt;ptr)) == -1) goto werr; &#125; dictReleaseIterator(di); di = NULL; /* So that we don't release it again on error. */ &#125; /* EOF opcode */ if (rdbSaveType(rdb,RDB_OPCODE_EOF) == -1) goto werr; /* CRC64 checksum. It will be zero if checksum computation is disabled, the * loading code skips the check in this case. */ cksum = rdb-&gt;cksum; memrev64ifbe(&amp;cksum); if (rioWrite(rdb,&amp;cksum,8) == 0) goto werr; return C_OK;werr: if (error) *error = errno; if (di) dictReleaseIterator(di); return C_ERR;&#125;// 各类型在rdb中的编码方式int rdbSaveKeyValuePair(rio *rdb, robj *key, robj *val, long long expiretime) &#123; int savelru = server.maxmemory_policy &amp; MAXMEMORY_FLAG_LRU; int savelfu = server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU; /* Save the expire time */ //如果设置了过期时间,先写过期时间 RDB_OPCODE_EXPIRETIME_MS = 252 if (expiretime != -1) &#123; if (rdbSaveType(rdb,RDB_OPCODE_EXPIRETIME_MS) == -1) return -1; // 8个字节长的时间 if (rdbSaveMillisecondTime(rdb,expiretime) == -1) return -1; &#125; /* Save the LRU info. */ // 如果设置了LRU策略,就要保存对象的lru信息,为了后面策略的执行 if (savelru) &#123; // 因为lru是相对时间,所以要修饰一下 uint64_t idletime = estimateObjectIdleTime(val); idletime /= 1000; /* Using seconds is enough and requires less space.*/ if (rdbSaveType(rdb,RDB_OPCODE_IDLE) == -1) return -1; if (rdbSaveLen(rdb,idletime) == -1) return -1; &#125; /* Save the LFU info. */ // 按频率的删除策略,要存储频率 if (savelfu) &#123; uint8_t buf[1]; buf[0] = LFUDecrAndReturn(val); /* We can encode this in exactly two bytes: the opcode and an 8 * bit counter, since the frequency is logarithmic with a 0-255 range. * Note that we do not store the halving time because to reset it * a single time when loading does not affect the frequency much. */ if (rdbSaveType(rdb,RDB_OPCODE_FREQ) == -1) return -1; if (rdbWriteRaw(rdb,buf,1) == -1) return -1; &#125; /* Save type, key, value */ // 存储对象类型 if (rdbSaveObjectType(rdb,val) == -1) return -1; // 存储key,一定是string对象类型 if (rdbSaveStringObject(rdb,key) == -1) return -1; // 存储值,key在类型为OBJ_STREAM和OBJ_MODULE中有用到 // 除了quicklist if (rdbSaveObject(rdb,val,key) == -1) return -1; return 1;&#125; rdbSaveObject String.会尝试存储成整形(编码为整数,或者长度小于11),长度大于20尝试LZF压缩 List.quickList,如果是压缩过的quickList(lzf),如果没有压缩过,保存string(sz) SET,hash编码按hash,如果是OBJ_ENCODING_INTSET转string保存 其他类似","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"读<<Redis设计与实现>>与redis(5.0)源码__对象","date":"2019-07-11T07:11:00.000Z","path":"2019/07/11/读-Redis设计与实现-与redis-5-0-源码-对象/","text":"redisObject 1234567891011 typedef struct redisObject &#123; unsigned type:4; // 类型,4位 unsigned encoding:4; // 编码 // 上次访问时间 // #define LRU_BITS 24 unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; // 引用次数 void *ptr; // 底层地址&#125; robj; type类型 1234567 #define OBJ_STRING 0 /* String object. */#define OBJ_LIST 1 /* List object. */#define OBJ_SET 2 /* Set object. */#define OBJ_ZSET 3 /* Sorted set object. */#define OBJ_HASH 4 /* Hash object. */#define OBJ_MODULE 5 /* Module object. */,Redis module 直接管理的#define OBJ_STREAM 6 /* Stream object. */ encoding编码 1234567891011 #define OBJ_ENCODING_RAW 0 /* Raw representation */#define OBJ_ENCODING_INT 1 /* Encoded as integer */#define OBJ_ENCODING_HT 2 /* Encoded as hash table */#define OBJ_ENCODING_ZIPMAP 3 /* Encoded as zipmap */ 主要在rdb里面使用#define OBJ_ENCODING_LINKEDLIST 4 /* No longer used: old list encoding. */#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#define OBJ_ENCODING_INTSET 6 /* Encoded as intset */#define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */#define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */#define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree of listpacks */ t_string 有三种编码方式,OBJ_ENCODING_INT,OBJ_ENCODING_EMBSTR,OBJ_ENCODING_RAW OBJ_ENCODING_EMBSTR_SIZE_LIMIT = 44,也就是小于等于44子长用embstr编码,大于就用raw.因为redisObject大小 = (4+4+24)/8+4+8 = 16,sdshdr8除去buf外的大小是3(len,alloc,flag),预留1byte的’\\0’,供20byte.redis的内存分配方法按2^n分配,所以最接近的是64,剩下44byte. tryObjectEncoding 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 /* Try to encode a string object in order to save space */robj *tryObjectEncoding(robj *o) &#123; long value; sds s = o-&gt;ptr; size_t len; /* Make sure this is a string object, the only type we encode * in this function. Other types use encoded memory efficient * representations but are handled by the commands implementing * the type. */ serverAssertWithInfo(NULL,o,o-&gt;type == OBJ_STRING); /* We try some specialized encoding only for objects that are * RAW or EMBSTR encoded, in other words objects that are still * in represented by an actually array of chars. */ if (!sdsEncodedObject(o)) return o; /* It's not safe to encode shared objects: shared objects can be shared * everywhere in the \"object space\" of Redis and may end in places where * they are not handled. We handle them only as values in the keyspace. */ if (o-&gt;refcount &gt; 1) return o; /* Check if we can represent this string as a long integer. * Note that we are sure that a string larger than 20 chars is not * representable as a 32 nor 64 bit integer. */ len = sdslen(s); // 20减去4个长度剩下16,2^64~=1.84E19(所以超过20位,减去符号19位,超过了int64表示的极限) if (len &lt;= 20 &amp;&amp; string2l(s,len,&amp;value)) &#123; // 是整数 /* This object is encodable as a long. Try to use a shared object. * Note that we avoid using shared integers when maxmemory is used * because every object needs to have a private LRU field for the LRU * algorithm to work well. */ // 如果设置了最大使用内存,说明要进行回收,不能有共享变量(要LRU) if ((server.maxmemory == 0 || !(server.maxmemory_policy &amp; MAXMEMORY_FLAG_NO_SHARED_INTEGERS)) &amp;&amp; value &gt;= 0 &amp;&amp; value &lt; OBJ_SHARED_INTEGERS) &#123; decrRefCount(o); incrRefCount(shared.integers[value]); return shared.integers[value]; &#125; else &#123; if (o-&gt;encoding == OBJ_ENCODING_RAW) sdsfree(o-&gt;ptr); o-&gt;encoding = OBJ_ENCODING_INT; o-&gt;ptr = (void*) value; return o; &#125; &#125; /* If the string is small and is still RAW encoded, * try the EMBSTR encoding which is more efficient. * In this representation the object and the SDS string are allocated * in the same chunk of memory to save space and cache misses. */ // 如果小于等于44,改用EMBSTR // 说明默认是RAW编码 if (len &lt;= OBJ_ENCODING_EMBSTR_SIZE_LIMIT) &#123; robj *emb; if (o-&gt;encoding == OBJ_ENCODING_EMBSTR) return o; emb = createEmbeddedStringObject(s,sdslen(s)); decrRefCount(o); return emb; &#125; /* We can't encode the object... * * Do the last try, and at least optimize the SDS string inside * the string object to require little space, in case there * is more than 10% of free space at the end of the SDS string. * * We do that only for relatively large strings as this branch * is only entered if the length of the string is greater than * OBJ_ENCODING_EMBSTR_SIZE_LIMIT. */ trimStringObjectIfNeeded(o); /* Return the original object. */ return o;&#125; t_list 编码方式有OBJ_ENCODING_QUICKLIST(OBJ_ENCODING_LINKEDLIST被弃用)(,OBJ_ENCODING_ZIPLIST在list里没用了) quicklist 将linkedlist和ziplist混合起来使用,每个节点是一个ziplist list-max-ziplist-size设置ziplist的大小,正数表示长度,负数表示 -n = 2^(n+1)kb t_hash 编码方式有OBJ_ENCODING_ZIPLIST,OBJ_ENCODING_HT 如果长度大于server.hash_max_ziplist_entries,转换成OBJ_ENCODING_HT 如果键值的长度大于 server.hash_max_ziplist_value,转换成OBJ_ENCODING_HT t_set 编码方式有OBJ_ENCODING_HT,OBJ_ENCODING_INTSET 如果长度大于server.set_max_intset_entries,或者有非整数,转换成OBJ_ENCODING_HT t_zset 编码方式有OBJ_ENCODING_ZIPLIST,OBJ_ENCODING_SKIPLIST 如果长度大于server.zset_max_ziplist_entries,或者有非整数,转换成OBJ_ENCODING_SKIPLIST 如果值的长度大于 server.zset_max_ziplist_value,转换成OBJ_ENCODING_SKIPLIST","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"读<<Redis设计与实现>>与redis(5.0)源码__ziplist","date":"2019-07-11T03:34:00.000Z","path":"2019/07/11/读-Redis设计与实现-与redis-5-0-源码-ziplist/","text":"ziplist构成 zlbytes- ztail- zllen- entrys-…- zlend uint32_t uint32_t uint16_t zlentry uint8_t 因为zlend使用固定值ZIP_END = 255作为结束标志(0xFF作为uint8的最大值,与prevlen单字节长度0xFE进行区别,同时是最后面的两个数作为标志(这个懂的吧)). zlentry 这个结构体只是用来接收存放信息的,只是为了方便操作,而并不是其在ziplist中的真正编码方式实际是:previous_entry_length-&gt; encoding -&gt; content 1234567891011121314151617181920212223 typedef struct zlentry &#123; // 前一个entry的字长 unsigned int prevrawlensize; /* Bytes used to encode the previous entry len*/ // unsigned int prevrawlen; /* Previous entry len. */ unsigned int lensize; /* Bytes used to encode this entry type/len. For example strings have a 1, 2 or 5 bytes header. Integers always use a single byte.*/ unsigned int len; /* Bytes used to represent the actual entry. For strings this is just the string length while for integers it is 1, 2, 3, 4, 8 or 0 (for 4 bit immediate) depending on the number range. */ unsigned int headersize; /* prevrawlensize + lensize. */ // 编码方式 unsigned char encoding; /* Set to ZIP_STR_* or ZIP_INT_* depending on the entry encoding. However for 4 bits immediate integers this can assume a range of values and must be range-checked. */ // 值 unsigned char *p; /* Pointer to the very start of the entry, that is, this points to prev-entry-len field. */&#125; zlentry; previous_entry_length 读取第一个字节是否为0xfe区分是1个字长还是5个字长(为什么是0xfe,因为0xff被用作结束标志) 1字节长,小于0xfe(244) 5字节长,第一字节是 0xfe,后面四个字节是实际长度 encoding 根据第一字节前2位,判断是整数还是字符串 前2位是00,01,10.这时候是字符串 00bbbbbb,后面6位表示content长度,(&lt;=2^6-1 = 63) 01bbbbbb xxxxxxxx,用后6位以及后面一个字节表示content长度,共14位(&lt;=16383) 10______ aaaaaaaa bbbbbbbb cccccccc dddddddd,5字节长,后4个字节表示长度(&lt;=2^32-1) 前2为是11.这时候是整数 11 00 0000,content长2,表示int16_t类型 11 01 0000,int32_t 11 10 0000,int64_t 11 11 0000,24位有符号整数 11 11 1110,8位有符号整数 11 11 xxxx,介于0-12的整数值,直接存在xxxx中","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"vimium","date":"2019-07-10T06:37:00.000Z","path":"2019/07/10/vimium/","text":"chrome扩展vimium github: https://github.com/philc/vimium 安装访问: chrome://extensions 在无痕模式下是无效的 使用说明 前缀 c=ctrl, m=meta, a=alt,大写+shift 当前页的操作 使用 ? 调出使用说明,快捷键列表 h,j,k,l 左下上右滚动 gg回到顶部 G到页面底部 d下滚半屏 u上滚半屏 f在当前tab打开链接 F在新tab打开链接 r刷新 gs查看源码 i 进入插入模式,其他键失效,知道ESC yy复制当前url yf复制链接url gf进入下一个frame gF回到上级frame 进入新页面的操作 o 打开URL,书签或者历史记录(提供搜索框) O 在新tab打开URL,书签或者历史记录(提供搜索框) b 打开书签 B 在新tab打开标签 使用查找功能 / 模式查找 n 向前搜索 N 向后搜索 历史 H 回退 L 前进 tab操作 J,gT 到上一个(左)tab K,gt 到下一个tab g0 到第一个tab g$ 到最后一个tab ^ 回到上一个访问的tab t 新建一个tab yt 复制当前tab x 关闭当前tab X 恢复已关闭tab T 在当前tab搜索 W 将当前tab移动到新窗口 固定/取消固定当前tab 使用标注 ma[bcd], mA 设置标注 使用 `a[bcd]回到标注的地方,`A全局标注可以跨tab `` 回到上一个jump之前的位置(包含gg,G,n,N,/,`a的跳转) 其他的浏览优化命令 ]],[[ 大概是在分页中定位到有next或者&gt;标签的地方,也就是上一页\\下一页 在新tab中打开多个链接 gi 聚焦到页面上第一个(第n个)文本输入框 gu 去url的上一级 gU 回到url的顶层(域名层) ge 编辑当前url gE 编辑当前url幷在新tab中打开 zH 左滑到底?(scroll all the way left) zL 右滑到底? v 视图模式,p/P 复制,y粘贴 V 视图行模式 自定义键 前往github查看","tags":[{"name":"其他","slug":"其他","permalink":"http://ipiao.top/tags/其他/"}]},{"title":"读<<Redis设计与实现>>与redis(5.0)源码__skiplist","date":"2019-07-09T02:06:00.000Z","path":"2019/07/09/读-Redis设计与实现-与redis-5-0-源码-skiplist/","text":"结构差异 结构定义在server.h文件方法实现在t_zset.c文件(ziplist是压缩) zskiplistNode 123456789 typedef struct zskiplistNode &#123; sds ele; // 原本是 robj *obj,表示保存的成员对象 double score; // 分值 struct zskiplistNode *backward; // 后退指针 struct zskiplistLevel &#123; struct zskiplistNode *forward; // 前进指针 unsigned long span; // 跨度 &#125; level[];&#125; zskiplistNode; zskiplist 12345 typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; // 表头和表尾 unsigned long length; // 长度,即节点数()不含表头 int level; // 跳跃表内层数最大的节点的层数&#125; zskiplist; 一些常量 ZSKIPLIST_P = 0.25,随机level的概率 ZSKIPLIST_MAXLEVEL = 64,最大level level的幂次定律 幂次定律: 越大的数出现的概率越小level为 n的概率大概是 (3/4)^n 1234567 int zslRandomLevel(void) &#123; int level = 1; // 每次1/4的概率往上加 while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125; API zslCreate 1234567891011121314151617 zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; zsl = zmalloc(sizeof(*zsl)); zsl-&gt;level = 1; zsl-&gt;length = 0; // 所以头节点是不计算长度的,而且初始化了最大的level但不计算level(算1) zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; zsl-&gt;header-&gt;level[j].forward = NULL; zsl-&gt;header-&gt;level[j].span = 0; &#125; zsl-&gt;header-&gt;backward = NULL; zsl-&gt;tail = NULL; return zsl;&#125; zslInsert 前提保证了元素不存在看起来有点复杂的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) &#123; // 更新数组,存储新node插入,各层需要修改的node,也就是新node在各层插入在哪个node之后 zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; // 排序数组,存着各层从header到update里面的node的跨度和 unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; // 非数字断言 serverAssert(!isnan(score)); x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 进行最大level次的遍历 /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; rank[i] += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; /* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */ level = zslRandomLevel(); // 如果随机出来的level更大,要补充update // update的值直接设置成header,跨度是length,因为是一步到达 if (level &gt; zsl-&gt;level) &#123; for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; zsl-&gt;level = level; &#125; x = zslCreateNode(level,score,ele); for (i = 0; i &lt; level; i++) &#123; // 每一层 // 把新node放在update[i]和它的forward之间 x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ // 因为之前的rank累积关系,新node和update之间的node跨度就是(rank[0] - rank[i]) // x-&gt;level[i].span而这个值很可能是1 // 在新加层里面,因为指向的是Null,所以span值没有关系 x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; // 因为新加了一个node,所以+1 &#125; /* increment span for untouched levels */ // 新层因为新节点的出现,是forward到新节点的,sapn+1 for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; // 第一层是顺序完全的 x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; zsl-&gt;length++; return x;&#125; zslDelete zslUpdateScore 是先delete,在insert,不复用","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"读<<Redis设计与实现>>与redis(5.0)源码__dict","date":"2019-07-04T08:39:00.000Z","path":"2019/07/04/读-Redis设计与实现-与redis-5-0-源码-dict/","text":"结构差异 dictEntry,该结构中union里面多了double类型d 12345678910 typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry; dict,多了一个迭代标志 1234567 typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict; 不知道是不是多出来的迭代器(adlist也有) 迭代器,大多用在rdb,aof,cluster场景中有safe的差异 12345678 typedef struct dictIterator &#123; dict *d; long index; int table, safe; dictEntry *entry, *nextEntry; /* unsafe iterator fingerprint for misuse detection. */ long long fingerprint; // 在非安全模式模式下,迭代的时候生成一个指纹,在后续再次处理相应键的时候,对比指纹是否一致,判断键值是否被修改&#125; dictIterator; dict一些参数 hash用的是siphash 强制负载因子 dict_force_resize_ratio = 5 最小的size是 DICT_HT_INITIAL_SIZE = 4(大小是2^n) dict_can_resize,在bgsave等情况下会设置成0 dictExpand 在rehash 过程中,dict是不会再次扩充的,那么有没有可能dict填满了,而还没有rehash完?不会,dicths的table是二维链表,size只是外层bucket的数量,幷不限制每个bucket的存储数量 12345678910111213141516171819202122232425262728293031323334353637 /* Expand or create the hash table */int dictExpand(dict *d, unsigned long size)&#123; /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // dictIsRehashing 返回 rehashidx &gt; -1 if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size) return DICT_ERR; dictht n; /* the new hash table */ // 返回下一个2^n,使得它大于等于size(最小是 DICT_HT_INITIAL_SIZE = 4) unsigned long realsize = _dictNextPower(size); /* Rehashing to the same table size is not useful. */ // 如果当前hashtable的使用长度到realsize相同,相当于没有扩充,是没有意义的 if (realsize == d-&gt;ht[0].size) return DICT_ERR; /* Allocate the new hash table and initialize all pointers to NULL */ // 分配新结构内存 n.size = realsize; n.sizemask = realsize-1; n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; /* Is this the first initialization? If so it's not really a rehashing * we just set the first hash table so that it can accept keys. */ if (d-&gt;ht[0].table == NULL) &#123; d-&gt;ht[0] = n; return DICT_OK; &#125; /* Prepare a second hash table for incremental rehashing */ d-&gt;ht[1] = n; d-&gt;rehashidx = 0; return DICT_OK;&#125; dictRehash 渐进式rehash过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 // n是rehash的bucket数量(不包含空的)int dictRehash(dict *d, int n) &#123; // 最大访问空的bucket数量 int empty_visits = n*10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ // 因为是从ht[0]迁移到ht[1]的过程,所以rehashidx自然要小于ht[0]的size assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx); // 访问到空bucket while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125; // de,非空bucket的(head)dictEntry de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while(de) &#123; uint64_t h; nextde = de-&gt;next; /* Get the index in the new hash table */ // 获取新bucket的索引,值超过sizemask后不是取余而是取与 h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; // 将当前 de放到新bucket的头,相当于对应的实现了一个'倒序' de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; /* Check if we already rehashed the whole table... */ // 如果used直接是0了,说明直接可以结束rehash了 if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125; rehash机制dictRehashMilliseconds 这个返回的rehashes的bucket数量不一定准确,因为rehash完成了就不会把最后一次的具体数量加进去,然后这个毫秒时间差异也不是精确的 12345678910 int dictRehashMilliseconds(dict *d, int ms) &#123; long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125; rehash机制_dictRehashStep 这个就简单了,迭代一个一个bucket去rehash 123 static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125; dict操作 比如dictAdd 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576 int dictAdd(dict *d, void *key, void *val)&#123; dictEntry *entry = dictAddRaw(d,key,NULL); if (!entry) return DICT_ERR; dictSetVal(d, entry, val); return DICT_OK;&#125;// 查找和替换都通过这个实现dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; long index; dictEntry *entry; dictht *ht; // 如果正在rehash,遇到add就执行一个bucket的rehash if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ // 这里是获取index的过程 // 如果existing不为nil,会将找到的值放进去然后直接返回 // 在addOrFind 和replace的时候,existing不是nil if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; /* Allocate the memory and store the new entry. * Insert the element in top, with the assumption that in a database * system it is more likely that recently added entries are accessed * more frequently. */ // 如在正在rehash就直接加到新ht里去 ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; entry = zmalloc(sizeof(*entry)); entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; ht-&gt;used++; /* Set the hash entry fields. */ // 涉及dict的type和keyDup dictSetKey(d, entry, key); return entry;&#125;// existing如果有值,那么用existing存储找到的值,幷不再返回索引static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing)&#123; unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; /* Expand the hash table if needed */ // 每次都会检查是否要expand // 如果正在rehash,返回OK // 如果还没初始化,调用dictExpand初始化 // 在used&gt;size的情况下,如果dict_can_resize或者used/size&gt;dict_force_resize_ratio,进行resize if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; // 这个过程,如果dict不在rehash,就遍历一次 // 如果rehash了就要遍历两次 for (table = 0; table &lt;= 1; table++) &#123; idx = hash &amp; d-&gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; if (existing) *existing = he; return -1; &#125; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break; &#125; return idx;&#125; dictGenericDelete 很简单,就是找到幷删除,然后在删除的时候区分是否释放内存如果是dictDelete的实现,是要释放内存的如果是dictUnlink,则不释放内存,在之后用dictFreeUnlinkedEntry释放内存,用在释放前,需要对它做其他操作而不影响其他增删改查.比如数据库server-&gt;db-&gt;dict对键dbAsyncDelete,zse里的del 123456789101112131415161718192021222324252627282930313233343536 static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) &#123; uint64_t h, idx; dictEntry *he, *prevHe; int table; if (d-&gt;ht[0].used == 0 &amp;&amp; d-&gt;ht[1].used == 0) return NULL; if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx]; prevHe = NULL; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; /* Unlink the element from the list */ if (prevHe) prevHe-&gt;next = he-&gt;next; else d-&gt;ht[table].table[idx] = he-&gt;next; if (!nofree) &#123; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); &#125; d-&gt;ht[table].used--; return he; &#125; prevHe = he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break; &#125; return NULL; /* not found */&#125; dict的type和privdata type,类型特定的函数,差不多是类函数的意思,因为dict有多种使用场景,其中的复制,对比,销毁函数有不同的实现,有点接口的意思 privdata,保存了需要传递给dict三个函数所需要的参数.比如,在dictReplace,如果key存在,执行dictSetVal,就是将旧值取出来,然后在privdata找到相关参数直接赋值过去 123456 #define dictSetVal(d, entry, _val_) do &#123; \\ if ((d)-&gt;type-&gt;valDup) \\ (entry)-&gt;v.val = (d)-&gt;type-&gt;valDup((d)-&gt;privdata, _val_); \\ else \\ (entry)-&gt;v.val = (_val_); \\&#125; while(0) 其他 随机获取,公平随机() **dictscan,实现了一个算法,最小消耗的动态迭代(可能有重复,单不会遗漏)","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"读<<Redis设计与实现>>与redis(5.0)源码__sds","date":"2019-07-04T02:58:00.000Z","path":"2019/07/04/读-Redis设计与实现-与redis-5-0-源码/","text":"主要是区别 sdshdr 不是单一的sdshdr结构,而是分了sdshdr5,sdshdr8,sdshdr16,sdshdr32,sdshdr64几种.鉴于对__attribute__的浅陋理解,是对某种结构属性的定义,也就是说可以当作同一个结构,然后在不同的场景,赋予了不同的结构属性.然后主要用flags的前三位(5种类型)来判断使用的是那种属性结构 123456789101112131415 // 这个不存在使用场景,只是给出理论上的属性结构struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;// 其他几种字段相同,但是len和alloc的类型结构跟着名称变struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ // 这里是总分配,书中是`free`,这里`free`用`sdsavail`计算得到 uint8_t alloc; /* excluding the header and null terminator */ // 多出来的类型标志 unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; #define SDS_MAX_PREALLOC (1024*1024) 这是重分配的1M空间临界定义字段 sdsReqType 这个函数没什么特殊的 123456789101112131415161718 tatic inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) return SDS_TYPE_16;// LONG_MAX大概是系统位数决定的最大数// LLONG_MAX大概是固定的64位最大数// 所以就是判断是32位还是64位的意思#if (LONG_MAX == LLONG_MAX) if (string_size &lt; 1ll&lt;&lt;32) return SDS_TYPE_32; return SDS_TYPE_64;#else // 所以如果是32位系统就没有使用sdshdr64一说了 return SDS_TYPE_32;#endif&#125; sdsnewlen 这个函数是主要功能,其他的很多函数都是调用它实现的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127 sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen); /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ // sdshdr5没有被使用的原因所在 if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8; int hdrlen = sdsHdrSize(type); unsigned char *fp; /* flags pointer. */ // 结构长度+buf长度+1(空格),没问题 // buf和结构的地址是连在一起的,一起分配 sh = s_malloc(hdrlen+initlen+1); if (init==SDS_NOINIT) init = NULL; else if (!init) // 初始化,sh设置成hdrlen+initlen+1)个字节长的0 memset(sh, 0, hdrlen+initlen+1); if (sh == NULL) return NULL; // 这个是s要指向buf的意思 s = (char*)sh+hdrlen; // flag pointer // 指针前移1位,说明flags也只是占用一个字节 fp = ((unsigned char*)s)-1; switch(type) &#123; case SDS_TYPE_5: &#123; // flags记录长度的时候用的是高5位 *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); break; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); // 这个大概就是指针指向sdshdr结构 sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen); // 把init的值copy到s去 s[initlen] = '\\0'; // 结尾 \\0 return s;&#125;5. sdsMakeRoomFor``` csds sdsMakeRoomFor(sds s, size_t addlen) &#123; void *sh, *newsh; size_t avail = sdsavail(s); size_t len, newlen; // 反正这个s[-1]是取到了flags的值 char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ // 剩余空间足够 if (avail &gt;= addlen) return s; len = sdslen(s); // sdshdr指针 sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); if (newlen &lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; // 加长之后新类型 type = sdsReqType(newlen); /* Don't use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ // 避免使用sdshdr5 if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) &#123; // 如果类型没有改变,直接给sh重新分配新空间 newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can't use realloc */ // 否则,新申请一个满足长度的空间 newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; // 把数据复制到新内存 memcpy((char*)newsh+hdrlen, s, len+1); // 释放旧内存 s_free(sh); // 重新赋值s s = (char*)newsh+hdrlen; // 重新定义s类型,即flags s[-1] = type; // 重新设置长度(会根据类型重新构建属性) sdssetlen(s, len); &#125; // 重新设置已分配长度 sdssetalloc(s, newlen); return s;&#125;","tags":[{"name":"redis","slug":"redis","permalink":"http://ipiao.top/tags/redis/"}]},{"title":"一次go内存泄漏调试","date":"2019-07-02T09:37:00.000Z","path":"2019/07/02/一次go内存泄漏调试/","text":"go性能调试工具 虽然不一定都需要 gv,go自带的pprof命令,实际上是Graphviz,搜索安装就可以了 web,同gv,不过是在浏览器中显示 go-torch,火焰图 案例背景 源自于同事的socket连接服务,服务启动一段时间后,内存飙升,呈现累积不下的现象,初步判断为内存泄漏(top下单个服务占用29G内存). 问题定位 找到函数 1 go tool pprof --inuse_space &#123;&#123;host&#125;&#125;/debug/pprof/heap 结果如下: 分析代码(由于代码变动,实际上137行移动到140行) 很明显是函数中msgData泄漏了.但是一开始在分析怎么泄漏的时候走了不少弯路 因为conn是socket连接,所以在一开始Read的时候,读出的数据包是要自定义解析的,初步判定msgLen值过大引起分配过大,至于为什么过大(是客户端传错了还是怎么的,暂不考虑,主要是也没打日志). 那么为什么分配过大会引起内存泄漏?因为go是自带gc的语言 弯路: 怀疑go线程泄漏(因为想当然的认为接下来的错误没有问题),于是去分析goroutine 一顿分析之后还是觉得不是goroutine的泄漏,很简单,因为前面内存泄漏是指向这个函数的 查看该函数相关的阻塞,当然肯定不是block里面的阻塞(为什么呢?因为这个函数很简单,msgData泄漏的唯一可能是这个变量没有被使用,于是怀疑上是阻塞).重新打开goroutine的pprof界面,搜索该方法及文件名,很快发现一些IO Wait状态线程,于是确定是阻塞 那么,唯一可能的阻塞,也正如heap文件指向的 140(137)行之后的io.ReadFull方法 一开始想到阻塞的时候甚至用byte.NewReader配合写了一个测试,然后否定了 再次定位确认的时候,只好查阅官方文档.话外的意思就是说,一开开始读到了,不够了,要遇到EOF才返回. 于是想到之前的测试用例,读完是有EOF的,本着严谨的态度确认一下去bytes包的文档,当然下面给出的是Buffer的注释(Reader下没有) 在去看一下net.Conn下的Read方法的注释,于是确认了这里这样读是会阻塞的 解决问题 设置最大的buffer值.该同学设置过,但是使用默认的设置值过大,没有效果.这样可以避免内存阻塞过大,但是解决不了阻塞问题 使用SetReadDeadline读取数据,这样就要在143行读取之后,再次将该值设置成0或者比较大的一个值,比较麻烦.","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime之HACKING.md","date":"2019-06-21T07:44:00.000Z","path":"2019/06/21/go-runtime之HACKING-md/","text":"HACKING.md 这是作者对runtime设计的一个阐述,翻译内容是这样的 这是一份原型文档,虽然在当下可能已经有点过时了.目的是讲述go程序运行原理,与我们写的go代码有什么不同.着重讲述一些大概的概念而不是详细的细节. 调度器结构 调度器管理了三种贯穿整个运行环境的资源:Gs,Ms和Ps.即时不需要操作运行环境也是需要了解的. Gs,Ms,Ps 一个”G”就可以简单的代表一个goroutine,有类型g表示,当一个goroutine退出,g对象就会被放在空闲g列表(池),之后被其他goroutine复用. 一个”M”代表一个可以真正执行用户代码,运行时代码以,系统调用,也可以空闲.由结构体m表示.在某一时刻可能有任意多的m,因为同时间可能发生任意多的系统调用 最后,一个”P”代表执行用户代码所需要的资源,比如调度器和内存分配状态,由结构体p表示.数量可以由GOMAXPROCS决定.一个P就像操作系统的CPU,p的内容就像每个CPU的状态.为了调度效率,将共享状态放在p中比放在每个m中或者每个g里面要好. 调度的工作是匹配G(要执行的代码),M(执行时机)和P(执行的资源和环境).当M停止执行用户代码的时候(比如发生系统调用的时候),将P放回P池,在恢复执行之前,再到P池里面取出一个P. 所有的g,m,p都是在堆里分配的,并且是不释放的资源,所以他们是稳定存在的,不需要运行时通过write barrier. 用户栈和系统栈 每个没有进入到死亡状态的G都有一个用户栈,是Go代码运行的地方.用户栈在开始分配的时候很小,在运行过程中动态增长或缩减 每个M都有一个系统栈(也就是M的”g0”栈,因为它是固定的),并且在Unix平台中有一个信号栈(gsignal).系统栈和信号栈不会增长,但是足以执行运行时代码和cgo代码(纯go二进制文件是8k;cgo由系统分配) 运行时经常会调用systemstack,mcall,或者asmcgocall临时地切换到系统栈取执行那些无法增长栈空间或者且切换用户goroutine的非抢占任务.在系统栈上运行的代码一定是非抢占式的,而且gc无法扫描系统栈.在系统栈上运行的时候,当前的用户栈也不是用来执行代码的. getg()和getg().m.curg 获取当前的用户g,用 getg().m.curg.getg()也返回当前的g,但是在系统栈或者信号栈执行代码的时候,这个方法返回的是当前m的”g0”或者”gsignal”. 所以可以用getg() == getg().m.curg判断当前是在用户栈上运行还是系统栈上运行 错误处理反馈 一般情况下,用户可以捕捉到panic进行处理(recover).但是,有一些情况,比如在系统栈上调用,或者在mallocgc时候调用的panic是灾难性的,无法恢复. 大部分在运行时抛出的错误是无法recover的.比如,用throw会立即抛出错误路径幷终止进程.一般情况下,throw应该传递一个常量string参数,避免不安全的分配.最终,在throw之前会打印出以”runtime”开头的错误信息. 为了runtime错误进行debug,可以加参数 GOTRACEBACK=system或者GOTRACEBACK=crash. 同步 运行时有很多不同的同步机制.这与语境上有关,比如goroutine调度上,和系统调度. 最简单的是 mutex, 只要使用lock和unlock就行了.这个用在短时间内保护共享结构.在mutex的是阻塞会直接阻塞m,与Go调度没什么关系.这意味着它是安全的也是runtime中最低级别的,因为阻碍了相关的G和P进行重调度.rwmutex也是一样的. 在一次性的通知情形下,使用note,提供了 notesleep和notewakeup两个方法.与传统UNIX系统中sleep/wakeup不同.note是一种无静态的调用,在调用notesleep或notewakeup之后立刻返回.note可以在用户调用noteclear之后重置,这也决定了note在sleep或者wakeup的时候不能有竟态.note和mutex一样,阻塞m,但是它进入睡眠状态的方式是不一样的:notesleep也阻碍了相关G和P的重调度,但是notetsleepg就像系统调用的阻塞,不影响在P上运行另一个G.当然,这仍然比阻塞G更低效. 用gopark和goready.gopark直接操作goroutine,将当前G放到等待队列幷从M/P就绪队列中移除,然后运行另一个就绪G,goready将一个停下的G重新放入就绪队列等待运行 总结一下,阻塞关系就是: Blocks Interface G M P (rw)mutex Y Y Y note Y Y Y/N park Y N N Atomics 运行时有自己的atomic包 runtime/internal/atomic,与sync/atomic对应,但是应为历史遗留问题,函数有不同的名称,还有一下附加的功能 一般而言,我们在运行时要慎重使用atomics,最好避免使用atomics操作.如果一个变量有可能被其他的同步机制锁保护,这个被保护的变量一般也不需要是原子的.这其中有个方面的理由: 使用non-atomic或者atomic会使得相应代码self-documenting.因为atomic的介入往往意味着有会有线程问题. non-atomic操作允许自动竟态检测,运行时虽然不会惊醒多线程静态检测,但是在不久的将来会.而atomic操作不允许竟态检测.而non-atomic允许你自定义的进行静态检测. non-atomic可以提升性能 当然,任何对共享变量的non-atomic操作都应该描述清楚如何进行保护 有些模式混用了atomic和non-atomic: Read-mostly 变量在更新的时候进行保护,而在锁定的时候,读操作不需要是原子的.在锁定区域外,读操作是原子的 在STW的读,因为在STW的时候不会发生写操作 也就是说,就像 Go Memory Model的观点,”Don’t be [too] clever”.这是在runtime里的情况,在其他地方也一样. Unmanaged memory(非托管内存?) 通常,runtime尝试使用正常的堆内存分配.但是,有时runtime必须在无法gc的地方(堆之外)进行分配,也就是unmanaged memory.这是必要的,如果对象是memory manager自己的或者调用方可能没有P. 有三种Unmanaged memory 分配机制 sysAlloc直接从操作系统中获取内存.内存可能来自各个分页,但是通过sysFree可以全部释放 fragmentation从小页中获取内存,联合成sysAlloc一样的,这样避免造成太多的内存碎片,但是正如它的名字,这些内存没有办法释放 fixalloc是SLAB算法分配内存的,它分配固定大小的内存,可以释放,但是这些内存只能由同一个fixalloc池复用.所以这些内存只能被同一种类型数据复用. 通常,使用以上方法分配内存的地方都会注释编译标记//go:notinheap. 在Unmanaged memory分配的对象,除了以下情况不许序包含堆指针. 任何Unmanaged memory里包含的堆内指针必须明确加入gc根(源)runtime.markroot 如果内存被复用,他们被标记为GC roots钱必须是零初始化的 Zero-initialization versus zeroing 在运行时有两种类型的零化,取决于内存是否已经初始化成类型安全的状态. 如果内存不是类型安全的,意味着它可能包含”garbage”,因为它刚被分配并且正在首次初始化,这种情况,必须使用zero-initialized,也就是memclrNoHeapPointers或者非指针写.这种情况下不会有写屏障write barriers. 如果内存已经是类型安全的并且简单的设置为零值了,那么必须使用typedmemclr或者memclrHasPointers,.这种方式有write barriers. Runtime-only compiler directives 除了”//go:”除了用在文档之外,还可以直接对编译进行干预 go:systemstack go:systemstack表示函数必须运行在系统栈,这会在函数的开始进行动态检查 go:nowritebarrier go:nowritebarrier让函数在出现write barriers的时候报错(无法阻止write barriers的生成,只是简单的插入) 通常的使用场景是,最好不要write barriers,但是不是必要的go:nowritebarrierrec. go:nowritebarrier go:nowritebarrierrec and go:yeswritebarrierrec go:nowritebarrierrec 让编译器在函数及其递归调用的的函数中在write barrier的时候抛出错误.相应的 go:yeswritebarrierrec保证编译器进行write barrier 逻辑上,编译器floods每个一go:nowritebarrierrec 开始的函数调用图,当遇到一个包含write barrier 的函数的时候.在go:yeswritebarrierrec是没有flood的 go:nowritebarrierrec用在write barrier的实现上,防止循环初始化 两种方式都是直接在调度器使用,write barrier需要一个有效P(getg().m.p != nil)而调度器代码经常不在一个有效P上运行.在这种情况,go:nowritebarrierrec使用在P的释放函数上,或者在没有P的时候,go:yeswritebarrierrec运行在重新获取P的函数上.因为有函数层级概念,释放和获取P要分成2个函数 go:notinheap go:notinheap运用在类型声明,这意味着一个类型绝不会在GC’d(不GC?)堆里分配.所以,这种类型的指针总是会在runtime.inheap的检查中失败.这种类型可以是全局变量,栈变量或者非托管内存对象( sysAlloc, persistentalloc,fixalloc分配). new(T), make([]T), append([]T, ...) 以及隐藏类型(泛型)分配是不允许的 正常类型的指针(不是unsafe.Pointer)不能被转换成一个go:notinheap 类型,即时它们有相同的底层 任何包含 go:notinheap类型的类型也是go:notinheap的,数组和结构体的元素是go:notinheap的,那么也是.map和channel不允许有go:notinheap.为了明确任何隐藏go:notinheap类型必须声明 在go:notinheap的指针上的Write barriers将被忽略 最后,go:notinheap真正的用处.运行时在低层级的内部结构中使用,以避免调度器和内存分配器上的memory barriers ,因为在这里他们是无效的,这种方式的安全的,也不会影响可读性.","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime之cpuprof.go","date":"2019-06-21T05:59:00.000Z","path":"2019/06/21/go-runtime之cpuprof-go-1/","text":"cpuProfile 123456789101112131415161718192021 type cpuProfile struct &#123; lock mutex on bool // profiling is on log *profBuf // profile events written here // extra holds extra stacks accumulated in addNonGo // corresponding to profiling signals arriving on // non-Go-created threads. Those stacks are written // to log the next time a normal Go thread gets the // signal handler. // Assuming the stacks are 2 words each (we don't get // a full traceback from those threads), plus one word // size for framing, 100 Hz profiling would generate // 300 words per second. // Hopefully a normal Go thread will get the profiling // signal at least once every few seconds. // extra累积着非Go创建的线程调用addNonGo获取的摘要标记,一旦有Go线程获得这些标记句柄,extra栈就会被写入日志文件 extra [1000]uintptr numExtra int lostExtra uint64 // count of frames lost because extra is full&#125; SetCPUProfileRate 12345678910111213141516171819202122232425262728293031323334353637383940 // SetCPUProfileRate sets the CPU profiling rate to hz samples per second.// If hz &lt;= 0, SetCPUProfileRate turns off profiling.// If the profiler is on, the rate cannot be changed without first turning it off.//// Most clients should use the runtime/pprof package or// the testing package's -test.cpuprofile flag instead of calling// SetCPUProfileRate directly.func SetCPUProfileRate(hz int) &#123;// Clamp hz to something reasonable. if hz &lt; 0 &#123; hz = 0 &#125; if hz &gt; 1000000 &#123; hz = 1000000 &#125; lock(&amp;cpuprof.lock) if hz &gt; 0 &#123; if cpuprof.on || cpuprof.log != nil &#123; print(\"runtime: cannot set cpu profile rate until previous profile has finished.\\n\") unlock(&amp;cpuprof.lock) return &#125; cpuprof.on = true // 设置cpufile 至少1个字头,32k数据,4k个tag cpuprof.log = newProfBuf(1, 1&lt;&lt;17, 1&lt;&lt;14) hdr := [1]uint64&#123;uint64(hz)&#125; cpuprof.log.write(nil, nanotime(), hdr[:], nil) setcpuprofilerate(int32(hz)) &#125; else if cpuprof.on &#123; // 直接关闭了profile setcpuprofilerate(0) cpuprof.on = false cpuprof.addExtra() cpuprof.log.close() &#125; unlock(&amp;cpuprof.lock)&#125; add 12345678910111213141516171819202122 func (p *cpuProfile) add(gp *g, stk []uintptr) &#123; // Simple cas-lock to coordinate with setcpuprofilerate. // 循环等待直到,获取信号锁 for !atomic.Cas(&amp;prof.signalLock, 0, 1) &#123; osyield() &#125; if prof.hz != 0 &#123; // implies cpuprof.log != nil if p.numExtra &gt; 0 || p.lostExtra &gt; 0 &#123; // 将extra信息写入文件 p.addExtra() &#125; hdr := [1]uint64&#123;1&#125; // Note: write \"knows\" that the argument is &amp;gp.labels, // because otherwise its write barrier behavior may not // be correct. See the long comment there before // changing the argument here. cpuprof.log.write(&amp;gp.labels, nanotime(), hdr[:], stk) &#125; atomic.Store(&amp;prof.signalLock, 0)&#125;","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime之chan*.go","date":"2019-06-20T02:22:00.000Z","path":"2019/06/20/go-runtime之chan-go/","text":"文件注释 12345678910 // Invariants:// At least one of c.sendq and c.recvq is empty,// except for the case of an unbuffered channel with a single goroutine// blocked on it for both sending and receiving using a select statement,// in which case the length of c.sendq and c.recvq is limited only by the// size of the select statement.//// For buffered channels, also:// c.qcount &gt; 0 implies that c.recvq is empty.// c.qcount &lt; c.dataqsiz implies that c.sendq is empty. 翻译一下:定式: 在无缓冲通道,除非send和rece都在单线程下阻塞, c.sendq和c.recvq至少有一个是空的,而且c.sendq和c.recvq的长度只受select语法限制 hchanSize 1 hchanSize = unsafe.Sizeof(hchan&#123;&#125;) + uintptr(-int(unsafe.Sizeof(hchan&#123;&#125;))&amp;(maxAlign-1)) 看结果是结构体hchan的实际大小,因为hchan的对齐值是8 func makechan(t chantype, size int) hchan 在makechan64(t *chantype, size int64) *hchan中,size不能越界 1234567 func makechan64(t *chantype, size int64) *hchan &#123; if int64(int(size)) != size &#123; panic(plainError(\"makechan: size out of range\")) &#125; return makechan(t, int(size))&#125; 元素类型大小不能超过64k 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 func makechan(t *chantype, size int) *hchan &#123; elem := t.elem // compiler checks this but be safe. // 意思大概是编译需要,实际上没有哪个的类型的大小会超过64k // 对应在sendDirect/recvDirect的typeBitsBulkBarrier里面的64k限制 if elem.size &gt;= 1&lt;&lt;16 &#123; throw(\"makechan: invalid channel element type\") &#125; // 基本上就是说elem的对齐了量不能超过 if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign &#123; throw(\"makechan: bad alignment\") &#125; // 1.size不能小于0 // 2.go内存内配限制,不允许分配大小超过限制 // 3.和2差不多意思 if size &lt; 0 || uintptr(size) &gt; maxSliceCap(elem.size) || uintptr(size)*elem.size &gt; maxAlloc-hchanSize &#123; panic(plainError(\"makechan: size out of range\")) &#125; // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG's are referenced from their owning thread so they can't be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. // Hchan存储元素与元素是否是指针值有关,具体体现在下面 var c *hchan switch &#123; case size == 0 || elem.size == 0: // 大概这就是无缓冲通道 c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = unsafe.Pointer(c) case elem.kind&amp;kindNoPointers != 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. // 如果是无指针类型,buf和hchan是一起分配的 c = (*hchan)(mallocgc(hchanSize+uintptr(size)*elem.size, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. // 这里hchan和buf是分开分配的 c = new(hchan) c.buf = mallocgc(uintptr(size)*elem.size, elem, true) &#125; c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) if debugChan &#123; print(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; elemalg=\", elem.alg, \"; dataqsiz=\", size, \"\\n\") &#125; return c&#125;type chantype struct &#123; typ _type elem *_type dir uintptr&#125; func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161 /* * generic single channel send/recv * If block is not nil, * then the protocol will not * sleep but return if it could * not complete. * * sleep can wake up with g.param == nil * when a channel involved in the sleep has * been closed. it is easiest to loop and re-run * the operation; we'll see that it's now closed. */func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; if c == nil &#123; if !block &#123; return false &#125; // 停止当前线程,幷设置好错误信息 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\"unreachable\") &#125; if debugChan &#123; print(\"chansend: chan=\", c, \"\\n\") &#125; // 大概是竟态检测 if raceenabled &#123; racereadpc(unsafe.Pointer(c), callerpc, funcPC(chansend)) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second c.recvq.first or c.qcount depending on kind of channel). // Because a closed channel cannot transition from 'ready for sending' to // 'not ready for sending', even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn't closed during the first observation. // 无缓冲通道如果没有接收者,无法完成 if !block &amp;&amp; c.closed == 0 &amp;&amp; ((c.dataqsiz == 0 &amp;&amp; c.recvq.first == nil) || (c.dataqsiz &gt; 0 &amp;&amp; c.qcount == c.dataqsiz)) &#123; return false &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) // 已关闭通道,直接panic if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(\"send on closed channel\")) &#125; // dequeue 会查找到一个sudog,如果有暂时从队列中删掉 if sg := c.recvq.dequeue(); sg != nil &#123; // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). // 如果存在(空闲的)sudog,直接将值send到接收方,而不管缓冲通道 send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true &#125; // 否则,在缓冲区未满的时候,将值放入缓冲区 if c.qcount &lt; c.dataqsiz &#123; // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) if raceenabled &#123; raceacquire(qp) racerelease(qp) &#125; // GO有write/read barrier // 涉及GC三色标记 // 作用应该是重新指定不可gc内存 typedmemmove(c.elemtype, qp, ep) // buf是循环引用的,标记可send指针 c.sendx++ if c.sendx == c.dataqsiz &#123; c.sendx = 0 &#125; c.qcount++ unlock(&amp;c.lock) return true &#125; // 不是阻塞发是不用加锁的 if !block &#123; unlock(&amp;c.lock) return false &#125; // Block on the channel. Some receiver will complete our operation for us. // 如果无缓冲空间可用了,阻塞通道 gp := getg() // 获取当前g mysg := acquireSudog() mysg.releasetime = 0 // 收集block信息的情况下,将releasetime设置为-1,估计是当作一个标记 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // enqueue 重新排队到队末(注意这个sudog不是程序自己写的receiver) c.sendq.enqueue(mysg) // 将当前g设置为阻塞等待(waiting)状态,直到被唤醒 goparkunlock(&amp;c.lock, waitReasonChanSend, traceEvGoBlockSend, 3) // someone woke us up. // 当被唤醒的时候,mysg不是当前g所等的waiting状态,这就是大问题了(当前g信息在阻塞期间被操作过) if mysg != gp.waiting &#123; throw(\"G waiting list is corrupted\") &#125; gp.waiting = nil if gp.param == nil &#123; if c.closed == 0 &#123; throw(\"chansend: spurious wakeup\") &#125; panic(plainError(\"send on closed channel\")) &#125; gp.param = nil // 记录阻塞事件 if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; mysg.c = nil // 主动释放这个从m缓冲池里取出来的sudog releaseSudog(mysg) return true&#125;// 这是acquireSudog的注释//go:nosplitfunc acquireSudog() *sudog &#123; // Delicate dance: the semaphore implementation calls // acquireSudog, acquireSudog calls new(sudog), // new calls malloc, malloc can call the garbage collector, // and the garbage collector calls the semaphore implementation // in stopTheWorld. // Break the cycle by doing acquirem/releasem around new(sudog). // The acquirem/releasem increments m.locks during new(sudog), // which keeps the garbage collector from being invoked. // 大意是说semaphore(信号?调用者?)调用acquireSudog直接new(sudog)的话, // new方法调用了malloc,malloc会调用gc,gc会再次调用semaphore,从而引发循环.打破循环的 // 方法是用acquirem/releasem,因为这个会屏蔽gc // 这里调用acquirem后获取m,幷从其缓存的sudog列表中取出最后一个 closechan 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 func closechan(c *hchan) &#123; if c == nil &#123; panic(plainError(\"close of nil channel\")) &#125; lock(&amp;c.lock) if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(\"close of closed channel\")) &#125; if raceenabled &#123; callerpc := getcallerpc() racewritepc(unsafe.Pointer(c), callerpc, funcPC(closechan)) racerelease(unsafe.Pointer(c)) &#125; c.closed = 1 // 这个先读后写,按顺序去除一个g,然后把所有的g通过schedlink连接到一起 var glist *g // release all readers for &#123; sg := c.recvq.dequeue() if sg == nil &#123; break &#125; if sg.elem != nil &#123; typedmemclr(c.elemtype, sg.elem) sg.elem = nil &#125; if sg.releasetime != 0 &#123; // 上面 releasetime = -1 的用处 sg.releasetime = cputicks() &#125; gp := sg.g gp.param = nil if raceenabled &#123; raceacquireg(gp, unsafe.Pointer(c)) &#125; gp.schedlink.set(glist) glist = gp &#125; // release all writers (they will panic) for &#123; sg := c.sendq.dequeue() if sg == nil &#123; break &#125; sg.elem = nil if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = nil if raceenabled &#123; raceacquireg(gp, unsafe.Pointer(c)) &#125; gp.schedlink.set(glist) glist = gp &#125; unlock(&amp;c.lock) // Ready all Gs now that we've dropped the channel lock. for glist != nil &#123; gp := glist glist = glist.schedlink.ptr() gp.schedlink = 0 goready(gp, 3) // goreadey解除程阻塞状态 &#125;&#125; chanrecv 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138 // chanrecv receives on channel c and writes the received data to ep.// ep may be nil, in which case received data is ignored.// If block == false and no elements are available, returns (false, false).// Otherwise, if c is closed, zeros *ep and returns (true, false).// Otherwise, fills in *ep with an element and returns (true, true).// A non-nil ep must point to the heap or the caller's stack.// ep 必须指向堆空间或者调用栈,主要是防gcfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // raceenabled: don't need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan &#123; print(\"chanrecv: chan=\", c, \"\\n\") &#125; if c == nil &#123; if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not ready for receiving, we observe that the // channel is not closed. Each of these observations is a single word-sized read // (first c.sendq.first or c.qcount, and second c.closed). // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. // // The order of operations is important here: reversing the operations can lead to // incorrect behavior when racing with a close. // 1. 非阻塞无缓冲没有发送方 // 2. 非阻塞有缓冲没有消息并且没有关闭(没有缓消息的另一种情况是数据直接发送到接收方而不是主动接收) if !block &amp;&amp; (c.dataqsiz == 0 &amp;&amp; c.sendq.first == nil || c.dataqsiz &gt; 0 &amp;&amp; atomic.Loaduint(&amp;c.qcount) == 0) &amp;&amp; atomic.Load(&amp;c.closed) == 0 &#123; return &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) // 没有关闭,没有消息 if c.closed != 0 &amp;&amp; c.qcount == 0 &#123; if raceenabled &#123; raceacquire(unsafe.Pointer(c)) &#125; unlock(&amp;c.lock) if ep != nil &#123; // clear标记白色,允许gc typedmemclr(c.elemtype, ep) &#125; return true, false &#125; if sg := c.sendq.dequeue(); sg != nil &#123; // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). // 发现发送者,基本上是阻塞(无缓冲/满缓冲)的发送者 // recv 方法:如果无缓冲,直接接收 // 如果有缓冲,肯定是满缓冲 recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true &#125; if c.qcount &gt; 0 &#123; // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled &#123; raceacquire(qp) racerelease(qp) &#125; if ep != nil &#123; // 赋值 typedmemmove(c.elemtype, ep, qp) &#125; // 移除 typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.qcount-- unlock(&amp;c.lock) return true, true &#125; if !block &#123; unlock(&amp;c.lock) return false, false &#125; // no sender available: block on this channel. // 没有发送方,也没有数量 // 和chansend相似的操作 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) goparkunlock(&amp;c.lock, waitReasonChanReceive, traceEvGoBlockRecv, 3) // someone woke us up if mysg != gp.waiting &#123; throw(\"G waiting list is corrupted\") &#125; gp.waiting = nil if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed&#125; chanrecv和chansend的block为false的情况 12345678910111213141516171819 func TestChan6(t *testing.T) &#123; var ch (chan int) select &#123; case c := &lt;-ch: t.Log(c) default: t.Log(\"default\") &#125;&#125;func TestChan7(t *testing.T) &#123; var ch (chan int) select &#123; case ch &lt;- 1: t.Log(1) default: t.Log(\"default\") &#125;&#125; default或其他条件的存在使得ch不是block读 补充: 1234567891011121314151617181920 // compiler implements//// select &#123;// case c &lt;- v:// ... foo// default:// ... bar// &#125;//// as//// if selectnbsend(c, v) &#123;// ... foo// &#125; else &#123;// ... bar// &#125;//func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) &#123; return chansend(c, elem, false, getcallerpc())&#125; 虽然文档说这样子是非阻塞调用,但是在debug的时候并没有见到该函数被调用!!","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime之pprof子包","date":"2019-06-19T02:22:00.000Z","path":"2019/06/19/go/","text":"elf.go 123 // elfBuildID returns the GNU build ID of the named ELF binary,// without introducing a dependency on debug/elf and its dependencies.func elfBuildID(file string) (string, error) 返回ELF二进制文件的GNU build ID label.go 通过 context.Context 上操作kv值,达到设置 label的目的 map.go 1234567891011121314151617181920 // A profMap is a map from (stack, tag) to mapEntry.// It grows without bound, but that's assumed to be OK.type profMap struct &#123; hash map[uintptr]*profMapEntry all *profMapEntry last *profMapEntry free []profMapEntry freeStk []uintptr&#125;// A profMapEntry is a single entry in the profMap.type profMapEntry struct &#123; nextHash *profMapEntry // next in hash list nextAll *profMapEntry // next in list of all entries stk []uintptr tag unsafe.Pointer count int64&#125;func (m *profMap) lookup(stk []uint64, tag unsafe.Pointer) *profMapEntry 大概是标签查找 pprof.go 定义了Profile 1234567 type Profile struct &#123; name string mu sync.Mutex m map[interface&#123;&#125;][]uintptr count func() int write func(io.Writer, int) error&#125; 初始化了一些Profile goroutine,threadcreate,heap,allocs,block,mutex 提供 NewProfile(name string) 方法支持自定义生成 func (p *Profile) Add(value interface{}, skip int) 将和value相关的执行栈加入到profile.Add在内部实现的map中存储value,所以value必须是可以被用作map的key,而且在没有收到移除(Remove)指令前不会被自动gc掉. writexxx proto.go 基本是构建pprof文件信息的方法 protobuf.go 编码,buffer protomem.go runtime.go 标记当前线程 internal子包 为了给外部调用,里面多封了一层profile包 encode.go 对Profile的编解码 filter.go 过滤 legacy_profile.go profile.go 123456789101112131415161718192021222324 // Profile is an in-memory representation of profile.proto.type Profile struct &#123; SampleType []*ValueType DefaultSampleType string Sample []*Sample Mapping []*Mapping Location []*Location Function []*Function Comments []string DropFrames string KeepFrames string TimeNanos int64 DurationNanos int64 PeriodType *ValueType Period int64 commentX []int64 dropFramesX int64 keepFramesX int64 stringTable []string defaultSampleTypeX int64&#125; profile.proto文件的内存信息","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime之debug子包","date":"2019-06-18T08:30:00.000Z","path":"2019/06/18/go-runtime之debug子包-1/","text":"garbage.go gc 状态 123456789 // gc状态集包含了最近的gc信息type GCStats struct &#123; LastGC time.Time // 上次gc时间 NumGC int64 // gc次数 PauseTotal time.Duration // 所有gc的总暂停时间 Pause []time.Duration // gc暂时时间历史记录,最近的在最前 PauseEnd []time.Time // gc暂停结束时间记录,最近的在最前 PauseQuantiles []time.Duration //&#125; ReadGCStats(stats *GCStats) 123456789 // ReadGCStats reads statistics about garbage collection into stats.// The number of entries in the pause history is system-dependent;// stats.Pause slice will be reused if large enough, reallocated otherwise.// ReadGCStats may use the full capacity of the stats.Pause slice.// If stats.PauseQuantiles is non-empty, ReadGCStats fills it with quantiles// summarizing the distribution of pause time. For example, if// len(stats.PauseQuantiles) is 5, it will be filled with the minimum,// 25%, 50%, 75%, and maximum pause times.func ReadGCStats(stats *GCStats) &#123; gc会根据PauseQuantiles的长度填充暂停时间 SetGCPercent(percent int) int 设置gc的比率,默认100,消极gc FreeOSMemory() 最大程度的释放系统内存 SetMaxStack(bytes int) int 设置单个goroutine的最大可用栈空间,64位默认1G,32位250M SetMaxThreads(threads int) int 设置最大可用的操作系统级别线程(M)数量 SetPanicOnFault(enabled bool) bool 设置当前goroutine是否在运行错误的时候进行panic WriteHeapDump(fd uintptr) 将堆以及堆对象的描述信息写进指定文件符.改操作会挂起所有线程直到全部写完.所以写入文件符对应的管道另一端不能是当前进程的,可以写入临时文件或者socket里 SetTraceback(level string) 设置Traceback的层级,”all”是全部 stack.go PrintStack() 将runtime.Stack返回的stack track输出到标准错误 Stack() 分配一个足够大的缓存容纳调用 runtime.Stack的返回.返回当前线程的格式化的stack trace. stubs.go 1234567 // Implemented in package runtime.func readGCStats(*[]time.Duration)func freeOSMemory()func setMaxStack(int) intfunc setGCPercent(int32) int32func setPanicOnFault(bool) boolfunc setMaxThreads(int) int 固有方法,在runtime里实现","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime之cgo子包","date":"2019-06-18T03:18:00.000Z","path":"2019/06/18/go-runtime之cgo子包/","text":"asm_{$GOARCH}.s 1234567 // Called by C code generated by cmd/cgo.// func crosscall2(fn func(a unsafe.Pointer, n int32, ctxt uintptr), a unsafe.Pointer, n int32, ctxt uintptr)// Saves C callee-saved registers and calls fn with three arguments.#ifndef GOOS_windowsTEXT crosscall2(SB),NOSPLIT,$0x50-0 /* keeps stack pointer 32-byte aligned */#elseTEXT crosscall2(SB),NOSPLIT,$0x110-0 /* also need to save xmm6 - xmm15 */ 参考 asm_amd64.s翻译一下: 被cmd/cgo生成的C代码crosscall2函数调用.C代码会保存在寄存器中幷被调用.从名字上看:大概是跨语言调用 callbacks_traceback.go 12345 //go:cgo_import_static x_cgo_callers//go:linkname x_cgo_callers x_cgo_callers//go:linkname _cgo_callers _cgo_callersvar x_cgo_callers bytevar _cgo_callers = &amp;x_cgo_callers callbacks.go 123456 // These utility functions are available to be called from code// compiled with gcc via crosscall2.// cgocallback is defined in runtime//go:linkname _runtime_cgocallback runtime.cgocallbackfunc _runtime_cgocallback(unsafe.Pointer, unsafe.Pointer, uintptr, uintptr) 翻译一下: 这个工具方法可以在gcc编译的代码,通过crosscall2方法调用. _runtime_cgo_panic_internal,_cgo_panic等参数或方法 gcc_{$GOARCH}.s 1234567891011 /* * void crosscall_amd64(void (*fn)(void)) * * Calling into the 6c tool chain, where all registers are caller save. * Called from standard x86-64 ABI, where %rbx, %rbp, %r12-%r15 * are callee-save so they must be saved explicitly. * The standard x86-64 ABI passes the three arguments m, g, fn * in %rdi, %rsi, %rdx. */.globl EXT(crosscall_amd64)EXT(crosscall_amd64): 参考 gcc_amd64.s翻译一下: 被cmd/cgo生成的C代码crosscall2函数调用.C代码会保存在寄存器中幷被调用.从名字上看:大概是跨语言调用 其他 都是gcc相关的一些初始化或简单设置功能","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"go-runtime包","date":"2019-06-14T10:27:00.000Z","path":"2019/06/14/go-runtime零/","text":"go runtime子包结构(v1.11) cgo debug internal atomic 大概是一些汇编代码和声明/定义了原子操作(不同平台的支持不一样) sys 定义了不同系统的参数值 msan pprof race 追踪基础 testdata trace runtime 模块(按文件名) alg.go 声明/定义了一些hash方法,和内存/指针有关,估计是为了方便查找用的 asm*.s 不知道具体干什么的,看起来和初始化有关 atomic_pointer.go 和 atomic*.s atomic*.s 给出了 .publicationBarrier (不知道干什么的)atomic_pointer.go 定义了原子操作交换指针/内存??的各种方法 cgo*.go 和c交互有关的各种函数 chan*.go channel 实现 complier.go 默认编译器名称 complex.go 复数实现,负数除法complex128div cpuprof.go debug.go 对debug包的支持,GOMAXPROCS方法会锁住调度进行STW. debugcall.go 提供对debugger函数调用的检查 def*.go 定义的一些系统参数 duff*.s makeduff.go生成的 env*.go 获取系统环境变量 extern.go go版本信息 fastlog2*.go log2 运算 float.go float64的操作 funcdata.h 用c定义的Go函数的基本信息字段 go_tls.h ??? hash*.go 内存哈希算法 heapdump.go 输出heap信息 iface.go interface{}相关实现 ifstack*.go // lfstack is the head of a lock-free stack.//// The zero value of lfstack is an empty list.//// This stack is intrusive. Nodes must embed lfnode as the first field.//// The stack does not keep GC-visible pointers to nodes, so the caller// is responsible for ensuring the nodes are not garbage collected// (typically by allocating them from manually-managed memory). lock*.go 锁实现 malloc*.go 内存分配实现? map*.go map 实现 mbarrier.go ??? mbitmap.go ??? mcache.go ??? mcentral.go ??? mem*.go 内存相关 memclr*.s memory clear memmove*.s memory move mfinal.go mfixalloc.go mgc*.go gc 相关 mheap.go mkduff.go mkfastlog2table.go mkfsizeclass.go mmap.go mprof.go msan*.s msan*.go mszie.go mstats.go mwbuff.go net_plan9.go netpoll*.go os*.go panic.go plugin.go print.go proc.go profbuf.go cpuprof写出的地方 proflabel.go race*.s race*.go rdebug.go relax_stub.go rt0*.s runtime*.go rwmutex*.go select.go sema.go sigaction.go signal*.go sigqueue.go sigtab*.go sizeclasses.go slice.go softfloat64.go stack.go string.go stubs*.go symtab.go sys*.go sys*.s syscall_nacl.h syscall*.go textflag.h time*.go tls* trace.go traceback.go type*.go unaligned*.go utf8.go vdso*.go vlop* wincallback.go write_err*.go zcallback_windows*","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"定时任务 crontab","date":"2019-06-10T09:43:00.000Z","path":"2019/06/10/定时任务-crontab-1/","text":"crontab 以下内容转载自 https://www.cnblogs.com/intval/p/5763929.html 主要是为了纪念犯了2次的错误,也就是下文的使用注意事项. 在执行性定时脚本的时候有时使用到其他命令要source xx_profile. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347 Linux定时任务Crontab命令详解linux 系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另 外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。一、crond简介crond 是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务 工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。Linux下的任务调度分为两类，系统任务调度和用户任务调度。系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。/etc/crontab文件包括下面几行：cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=HOME=/# run-parts51 * * * * root run-parts /etc/cron.hourly24 7 * * * root run-parts /etc/cron.daily22 4 * * 0 root run-parts /etc/cron.weekly42 4 1 * * root run-parts /etc/cron.monthly前 四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行 命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务 执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。使用者权限文件：文件：/etc/cron.deny说明：该文件中所列用户不允许使用crontab命令文件：/etc/cron.allow说明：该文件中所列用户允许使用crontab命令文件：/var/spool/cron/说明：所有用户crontab文件存放的目录,以用户名命名crontab文件的含义：用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：minute hour day month week command其中：minute： 表示分钟，可以是从0到59之间的任何整数。hour：表示小时，可以是从0到23之间的任何整数。day：表示日期，可以是从1到31之间的任何整数。month：表示月份，可以是从1到12之间的任何整数。week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。在以上各个字段中，还可以使用以下特殊字符：星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。二、crond服务安装crontab：yum install crontabs服务操作说明：/sbin/service crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置/sbin/service crond status //启动服务查看crontab服务是否已设置为开机启动，执行命令：ntsysv加入开机自动启动：chkconfig –level 35 crond on三、crontab命令详解1．命令格式：crontab [-u user] filecrontab [-u user] [ -e | -l | -r ]2．命令功能：通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。3．命令参数：-u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。-e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。-l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。-r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。-i：在删除用户的crontab文件时给确认提示。4．常用方法：1). 创建一个新的crontab文件在 考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑 crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其 中加入这样一行：EDITOR=vi; export EDITOR然后保存并退出。不妨创建一个名为&lt;user&gt; cron的文件，其中&lt;user&gt;是用户名，例如， davecron。在该文件中加入如下的内容。# (put your own initials here)echo the date to the console every# 15minutes between 6pm and 6am0,15,30,45 18-06 * * * /bin/echo ‘date’ &gt; /dev/console保存并退出。确信前面5个域用空格分隔。在 上面的例子中，系统将每隔1 5分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些 系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为 cron命令的参数：$ crontab davecron现在该文件已经提交给cron进程，它将每隔1 5分钟运行一次。同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。2). 列出crontab文件为了列出crontab文件，可以用：$ crontab -l0,15,30,45,18-06 * * * /bin/echo `date` &gt; dev/tty1你将会看到和上面类似的内容。可以使用这种方法在$ H O M E目录中对crontab文件做一备份：$ crontab -l &gt; $HOME/mycron这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。3). 编辑crontab文件如果希望添加、删除或编辑crontab文件中的条目，而E D I TO R环境变量又设置为v i，那么就可以用v i来编辑crontab文件，相应的命令为：$ crontab -e可以像使用v i编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， c r o n会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。我们在编辑crontab文件时，没准会加入新的条目。例如，加入下面的一条：# DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month30 3 1,7,14,21,26 * * /bin/find -name “core’ -exec rm &#123;&#125; \\;现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。现在让我们使用前面讲过的crontab -l命令列出它的全部信息：$ crontab -l# (crondave installed on Tue May 4 13:07:43 1999)# DT:ech the date to the console every 30 minites0,15,30,45 18-06 * * * /bin/echo `date` &gt; /dev/tty1# DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month30 3 1,7,14,21,26 * * /bin/find -name “core’ -exec rm &#123;&#125; \\;4). 删除crontab文件要删除crontab文件，可以用：$ crontab -r5). 恢复丢失的crontab文件如果不小心误删了crontab文件，假设你在自己的$ H O M E目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/&lt;username&gt;，其中&lt;username&gt;是用户名。如果由于权限问题无法完成拷贝，可以用：$ crontab &lt;filename&gt;其中，&lt;filename&gt;是你在$ H O M E目录中副本的文件名。我建议你在自己的$ H O M E目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按&lt;Ctrl-D&gt;，否则你将丢失crontab文件。5．使用实例实例1：每1分钟执行一次command命令：* * * * * command实例2：每小时的第3和第15分钟执行命令：3,15 * * * * command实例3：在上午8点到11点的第3和第15分钟执行命令：3,15 8-11 * * * command实例4：每隔两天的上午8点到11点的第3和第15分钟执行命令：3,15 8-11 */2 * * command实例5：每个星期一的上午8点到11点的第3和第15分钟执行命令：3,15 8-11 * * 1 command实例6：每晚的21:30重启smb 命令：30 21 * * * /etc/init.d/smb restart实例7：每月1、10、22日的4 : 45重启smb 命令：45 4 1,10,22 * * /etc/init.d/smb restart实例8：每周六、周日的1 : 10重启smb命令：10 1 * * 6,0 /etc/init.d/smb restart实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 命令：0,30 18-23 * * * /etc/init.d/smb restart实例10：每星期六的晚上11 : 00 pm重启smb 命令：0 23 * * 6 /etc/init.d/smb restart实例11：每一小时重启smb 命令：* */1 * * * /etc/init.d/smb restart实例12：晚上11点到早上7点之间，每隔一小时重启smb 命令：* 23-7/1 * * * /etc/init.d/smb restart实例13：每月的4号与每周一到周三的11点重启smb 命令：0 11 4 * mon-wed /etc/init.d/smb restart实例14：一月一号的4点重启smb 命令：0 4 1 jan * /etc/init.d/smb restart实例15：每小时执行/etc/cron.hourly目录内的脚本命令：01 * * * * root run-parts /etc/cron.hourly说明：run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了四、使用注意事项注意环境变量问题有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。在 crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程 序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这 样，系统执行任务调度时就没有问题了。不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点：1）脚本中涉及文件路径时写全局路径；2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如：cat start_cbp.sh#!/bin/shsource /etc/profileexport RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf/usr/local/jboss-4.0.5/bin/run.sh -c mev &amp;3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如：0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh注意清理系统用户的邮件日志每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。例如，可以在crontab文件中设置如下形式，忽略日志输出：0 */3 * * * /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1“/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。系统级任务调度与用户级任务调度系 统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么 做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc /crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个 定时重启系统的任务也是无效的。其他注意事项新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\\%Y\\%m\\%d’。","tags":[{"name":"sh","slug":"sh","permalink":"http://ipiao.top/tags/sh/"}]},{"title":"一些好用的东西","date":"2019-06-04T08:42:00.000Z","path":"2019/06/04/一些好用的东西/","text":"golang包 haha~! 科普博客 go-torch火焰图 vim使用进阶 go-micro实践 appium简介 资源网站 天赋好书 前端开发博客 tushare Redis 设计与实现 大神博客 鸟窝 面向信仰编程 徐旭的个人博客","tags":[]},{"title":"go-命令","date":"2019-06-04T08:34:00.000Z","path":"2019/06/04/读go源码/","text":"go命令 翻译一遍^_^ 12345678910111213141516171819202122232425 build compile packages and dependenciesclean remove object filesdoc show documentation for package or symbolenv print Go environment informationfix run go tool fix on packagesfmt run gofmt on package sourcesgenerate generate Go files by processing sourceget download and install packages and dependenciesinstall compile and install packages and dependencieslist list packagesrun compile and run Go programtest test packagestool run specified go toolversion print Go versionvet run go tool vet on packages// Additional help topics:c calling between Go and Cbuildmode description of build modesfiletype file typesgopath GOPATH environment variableimportpath import path syntaxpackages description of package liststestflag description of testing flagstestfunc description of testing functions build(编译包和依赖) 编译包及其依赖但是不安装(install).如果包参数是一列,把它们当作一个包的源码文件处理如果是main包,编译出结果幷保存,否则只编译(相当于检查能否编译)-o 指定输出文件名.如果没有指定,不是main包取package.+第一个文件名,如果是main包,取第一个文件名.(go build init.go main.go =&gt; init)-i 按装其依赖包 用法 1 go build [-o output] [-i] [build flags] [packages] 参数(build, clean, get, install, list, run, test 共享) 123456789101112131415161718192021222324252627282930 -a 强行对所有涉及到的代码包（包含标准库中的代码包）进行重新构建。-n 打印编译期间所用到的其它命令，但是并不真正执行它们。-p n 指定编译过程中执行各任务的并行数量（确切地说应该是并发数量）。在默认情况下，该数量等于CPU的逻辑核数。但是在darwin/arm平台（即iPhone和iPad所用的平台）下，该数量默认是1。-race 开启竞态条件的检测。不过此标记目前仅在linux/amd64、freebsd/amd64、darwin/amd64和windows/amd64平台下受到支持。-v 打印出那些被编译的代码包的名字。-work 打印出编译时生成的临时工作目录的路径，并在编译结束时保留它。在默认情况下，编译结束时会删除该目录。-x 打印编译期间所用到的其它命令。注意它与-n标记的区别。-buildmode mode 详情查看 'go help buildmode'-linkshared buildmode=shared下的链接库-compiler name 指定编译器名称(gccgo or gc).默认gc-gccgoflags 'arg list' 给gccgo编译器调用的参数-gcflags 'arg list' 给gc编译器调用的参数-installsuffix suffix 为了使当前的输出目录与默认的编译输出目录分离，可以使用这个标记。此标记的值会作为结果文件的父目录名称的后缀。其实，如果使用了-race标记，这个标记会被自动追加且其值会为race。如果我们同时使用了-race标记和-installsuffix，那么在-installsuffix标记的值的后面会再被追加_race，并以此来作为实际使用的后缀。-ldflags 'flag list' 此标记用于指定需要传递给go tool link命令的标记的列表。-asmflags 'flag list' 此标记可以后跟另外一些标记，如-D、-I、-S等。这些后跟的标记用于控制Go语言编译器编译汇编语言文件时的行为。-tags 'tag list' 此标记用于指定在实际编译期间需要受理的编译标签（也可被称为编译约束）的列表。这些编译标签一般会作为源码文件开始处的注释的一部分.-toolexec 'cmd args' 此标记可以让我们去自定义在编译期间使用一些Go语言自带工具（如vet、asm等）的方式。 列表参数接收以空格间隔的列表.参数-数量可1可2更多参见 go help packages,go help gopath,go help c,go install, go get, go clean 等 clean(移除对象文件) 用法 1 go clean [-i] [-r] [-n] [-x] [build flags] [packages] 执行go clean命令会删除掉执行其它命令时产生的一些文件和目录，包括： 在使用go build命令时在当前代码包下生成的与包名同名或者与Go源码文件同名的可执行文件。在Windows下，则是与包名同名或者Go源码文件同名且带有“.exe”后缀的文件。 在执行go test命令并加入-c标记时在当前代码包下生成的以包名加“.test”后缀为名的文件。在Windows下，则是以包名加“.test.exe”后缀为名的文件。我们会在后面专门介绍go test命令。 如果执行go clean命令时带有标记-i，则会同时删除安装当前代码包时所产生的结果文件。如果当前代码包中只包含库源码文件，则结果文件指的就是在工作区的pkg目录的相应目录下的归档文件。如果当前代码包中只包含一个命令源码文件，则结果文件指的就是在工作区的bin目录下的可执行文件。 还有一些目录和文件是在编译Go或C源码文件时留在相应目录中的。包括：“_obj”和“_test”目录，名称为“_testmain.go”、“test.out”、“build.out”或“a.out”的文件，名称以“.5”、“.6”、“.8”、“.a”、“.o”或“.so”为后缀的文件。这些目录和文件是在执行go build命令时生成在临时目录中的。如果你忘记了这个临时目录是怎么回事儿，可以再回顾一下前面关于go build命令的介绍。临时目录的名称以go-build为前缀。 如果执行go clean命令时带有标记-r，则还包括当前代码包的所有依赖包的上述目录和文件。 doc(展示包文档) 用法 123 -c 加入此标记后会使go doc命令区分参数中字母的大小写。默认情况下，命令是大小写不敏感的。-cmd 加入此标记后会使go doc命令同时打印出main包中的可导出的程序实体（其名称的首字母大写）的文档。默认情况下，这部分文档是不会被打印出来的。-u 加入此标记后会使go doc命令同时打印出不可导出的程序实体（其名称的首字母小写）的文档。默认情况下，这部分文档是不会被打印出来的。 godoc 有更丰富的功能 env(打印go环境信息) fix(对包运行go tool fix) install(编译幷安装) 相比较go build,除了编译还多了安装步骤.没有 -o 指输出文件的操作在 GOPATH 有多个路径的时候,如果是安装命令源码 (main 包),要设置环境变量GOBIN.安装库源码的时候会默认安装到第一个GOPATH下的 pkg 下的${GOOS}_${GOARCH}文件夹. (go get 类似)标准库的.a静态文件会被安装到GOROOT的pkg中 get(下载并安装) 从 VCS(version control system) 中下载并安装可以通过在仓库中设置go标签或分支,只能检出对应版本代码,否则master-u 强制更新,重新下载拉取通过导入注释,自定义导入url package analyzer // import &quot;hypermind.cn/talon/analyzer&quot;html 导入标签 &lt;meta name=&quot;go-import&quot; content=&quot;import-prefix vcs repo-root&quot;&gt;,如: &lt;meta name=&quot;go-import&quot; content=&quot;hypermind.cn/talon git https://github.com/hyper-carrot/talon&quot;&gt; 特有标签 123456 -d 让命令程序只执行下载动作，而不执行安装动作。-f 仅在使用-u标记时才有效。该标记会让命令程序忽略掉对已下载代码包的导入路径的检查。如果下载并安装的代码包所属的项目是你从别人那里Fork过来的，那么这样做就尤为重要了。-fix 让命令程序在下载代码包后先执行修正动作，而后再进行编译和安装。-insecure 允许命令程序使用非安全的scheme（如HTTP）去下载指定的代码包。如果你用的代码仓库（如公司内部的Gitlab）没有HTTPS支持，可以添加此标记。请在确定安全的情况下使用它。-t 让命令程序同时下载并安装指定的代码包中的测试源码文件中依赖的代码包。-u 让命令利用网络来更新已有代码包及其依赖包。默认情况下，该命令只会从网络上下载本地不存在的代码包，而不会更新已有的代码包。","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"}]},{"title":"pyenv 安装","date":"2019-06-04T06:04:00.000Z","path":"2019/06/04/pyenv-安装/","text":"pyenv 安装过程 参考: https://github.com/pyenv/pyenv 参考: https://github.com/pyenv/pyenv/wiki 以bash/centos 为例 pyenv安装路径(也是之后的多版本根路径) 1 git clone https://github.com/pyenv/pyenv.git ~/.pyenv 设置环境变量 12 echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.bash_profileecho 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.bash_profile 在shell启动后执行 pyenv init,确保在后面执行,依赖PATH 1 echo -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval \"$(pyenv init -)\"\\nfi' &gt;&gt; ~/.bash_profile 重启shell 123 exec \"$SHELL\"# 如果不行(执行pyenv没反应)source ~/.bash_profile 安装python的构建依赖 1 yum install gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-devel tk-devel libffi-devel 更换pyenv下载源(更换缓存) 12 v=3.7.1;wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v// 思想是下载国内镜像到 $PYENV_ROOT/cache 下,然后pyenv install直接安装 安装 pyenv-virtualenv 幷初始化设置 123 git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenvecho 'eval \"$(pyenv virtualenv-init -)\"' &gt;&gt; ~/.bash_profile","tags":[{"name":"sh","slug":"sh","permalink":"http://ipiao.top/tags/sh/"},{"name":"python","slug":"python","permalink":"http://ipiao.top/tags/python/"}]},{"title":"docker安装","date":"2019-04-27T04:48:00.000Z","path":"2019/04/27/docker安装/","text":"正式环境不能像开发环境一样随意.. 网桥 12345678910 cat &gt;&gt; /etc/sysctl.conf&lt;&lt;EOFnet.ipv4.ip_forward=1net.bridge.bridge-nf-call-iptables=1net.ipv4.neigh.default.gc_thresh1=4096net.ipv4.neigh.default.gc_thresh2=6144net.ipv4.neigh.default.gc_thresh3=8192EOF# 这个其实是重启命令init 6 如果已经安装高版本Docker,可进行降级安装(可选) 1 yum downgrade --setopt=obsoletes=0 -y docker-ce-$&#123;version&#125; docker-ce-selinux-$&#123;version&#125; 卸载旧版本Docker软件 123456789101112131415161718192021222324 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ container*sudo adduser dockersudo echo 'docker ALL=(ALL) ALL' &gt;&gt; /etc/sudoersexport docker_version=17.03.2sudo yum update -ysudo yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completionsudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo yum makecache allversion=$(yum list docker-ce.x86_64 --showduplicates | sort -r|grep $&#123;docker_version&#125;|awk '&#123;print $2&#125;')sudo yum -y install --setopt=obsoletes=0 docker-ce-$&#123;version&#125; docker-ce-selinux-$&#123;version&#125;sudo usermod -aG docker dockersudo systemctl enable docker 物理机需要增加overlay2，云服务器已是overlay2。不需要这配置 123456789101112131415161718 vi /etc/docker/daemon.json&#123;\"max-concurrent-downloads\": 3,\"max-concurrent-uploads\": 5,\"registry-mirrors\": [\"https://a9wm3lf0.mirror.aliyuncs.com\"],\"graph\": \"/home/docker\",\"storage-driver\": \"overlay2\",\"storage-opts\": [\"overlay2.override_kernel_check=true\"],\"log-driver\": \"json-file\",\"log-opts\": &#123; \"max-size\": \"100m\", \"max-file\": \"3\" &#125;&#125; WARNING: bridge-nf-call-ip6tables is disabled 123456 vi /etc/sysctl.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1sysctl -p","tags":[{"name":"sh","slug":"sh","permalink":"http://ipiao.top/tags/sh/"}]},{"title":"sh字符串截取","date":"2019-04-27T04:17:00.000Z","path":"2019/04/27/sh字符串截取/","text":"sh字符串截取 *的位置,代表删除侧边 #号截取，* 删除从左边满足条件的第一组字符及其左边字符，保留右边字符。 123 var=http://www.aaa.com/123.htm.echo $&#123;var#*//&#125; # www.aaa.com/123.htm.echo $&#123;var#*/&#125; # /www.aaa.com/123.htm. ##号截取，* 删除从右边满足条件的第一组字符及其左边字符，保留右边字符 123 var=http://www.aaa.com/123.htm.echo $&#123;var##*//&#125; # www.aaa.com/123.htm.echo $&#123;var##*/&#125; # 123.htm. %号截取，* 删除从左边满足条件的第一组字符及其左边字符，保留左边字符 123 var=http://www.aaa.com/123.htm.echo $&#123;var%//*&#125; # http:echo $&#123;var%/*&#125; # http://www.aaa.com %%号截取，* 删除从右边满足条件的第一组字符及其左边字符，保留左边字符 123 var=http://www.aaa.com/123.htm.echo $&#123;var%%//*&#125; # http:echo $&#123;var%%/*&#125; # http: 下标截取(开始位置+长度)(负数下标表示从右边数) 123 var=http://www.aaa.com/123.htm.echo $&#123;var:0:5&#125; # http:echo $&#123;var:0:-1&#125; # http://www.aaa.com/123.htm. 缺省下标(个数)截取 12 var=http://www.aaa.com/123.htm.echo $&#123;var:5&#125; # www.aaa.com/123.htm.","tags":[{"name":"sh","slug":"sh","permalink":"http://ipiao.top/tags/sh/"}]},{"title":"ssh-config","date":"2019-04-27T03:52:00.000Z","path":"2019/04/27/ssh-config/","text":"ssh 配置说明 位置:一般是 ~/./ssh/config,文件存在直接创建即可. 格式: 1234567 Host test # 随意命名 HostName 118.25.7.38 User root Port 22 IdentityFile ~/.ssh/id_rsa # 指定密钥文件 # ProxyCommand ssh test2 -W '%h %p' # 跳板机跳转 # ProxyCommand sshpass -p pwd ssh %u@%h # 账号密码免输入密码登录 通过 ssh test 就可以登录服务器 ssh-keygen -t rsa 生成自己的密钥 ssh-copy-id 可以在账号密码登录后将自己的密钥拷贝到服务器,以后就可以不用账号密码(支持的情况下) ssh 执行多命令(其实是 &lt;&lt; EOF 的使用) 1234567 ssh $host &lt;&lt;EOF cd $path mv $tmpbinaryname $binaryname cp $binaryname $cmd cd $cmd nohup ./$binaryname 2&gt;&amp;1 &amp;EOF 6.1 脚本执行可能会在退出的时候切断服务,是由于进程间的依赖关系造成的,可以加 setsid, 如 setsid nohup ./$binaryname 2&gt;&amp;1 &amp; scp, 依赖ssh. scp $binaryname $host:$path/$tmpbinaryname,上传到服务器 7.1 scp $host:$path/$tmpbinaryname $binaryname,反过来就是从服务器下载","tags":[{"name":"sh","slug":"sh","permalink":"http://ipiao.top/tags/sh/"}]},{"title":"文件监听 inotify","date":"2019-04-27T03:17:00.000Z","path":"2019/04/27/文件监听-inotify/","text":"inotify文件事件的自动化部署 需要安装,补充inotify命令inotify-tools,inotifywait. 1 sudo apt-get(yum) install inotify-tools inotifywait -h 了解其使用方法 基于文件事件的自动化部署 1.需求: 由于公司所有服务器采用跳板机(jumpserver)登录方式,目前无法通过任何方式进行直连以及文件的直接传输,于是乎,程序更新部署(尤其是测试环境)显得及其麻烦.当前只能通过将程序文件上传(ftp)到目的服务器临时目录 /tmp,然后再进行二次操作. 2.解决方案: 考虑二次操作,有几个解决方案,其中2个比较代表性的是: 2.1 通过supervisord配置,界面管理重启. 2.2 通过文件监听inotifywait自己实现监听重启脚本 3.方案对比 3.1 supervisord劣势: 需要额外的配置文件,需要开放管理界面端口,(根据以往的经验,)容易失效 3.2 supervisord优势: 界面管理,可以随时重启当前服务 3.3 inotifywait劣势: 每次重启需要手动出发事件(相当于去supervisord界面点击一下),但是要通过jumpserver的界面去操作,中间多了好几步. 3.4 inotifywait优势: 安装简单(就是一个安装命令和一个监听脚本),根据自己的服务特性写脚本足够灵活(不必重复的配置文件) 微服务配置脚本 由于完全自己开发,所有的脚本,配置格式都比较统一,所以脚本不会复杂 1234567891011121314151617181920212223242526272829303132333435363738394041424344 #!/usr/bin/env bash# 监听文件夹改动并自动编译重启SRCDIR=`pwd`dorestart()&#123; sleep 2 echo \"restart $1\" cd \"/srv/onevideo/$1\" f=\"1v1_$1\" tmpfile=\"/tmp/onevideo/$1/$f\" if [ ! -f $tmpfile ]; then return fi setsid sh restart.sh &amp; # mv $tmpfile ./ # chmod +x $f # ps -aux|grep $f|grep -v grep|awk '&#123;print $2&#125;'|xargs kill -15 # 2|3|15 # sleep 2 # dt=`date \"+%m%d_%H%M\"` # if [ ! -d logs_bak ]; then # mkdir logs_bak # fi # mv \"$1.log\" \"logs_bak/$1\"_\"$dt.log\" # setsid nohup ./$f -c \"server.yaml\" --registry_address \"127.0.0.1:8500\" 2&gt;&amp;1 &gt;&gt;\"$1.log\" &amp; cd $SRCDIR if [ ! -f \"$1/EOF\" ]; then touch \"$1/EOF\" fi # setsid sh restart.sh &amp; echo \"restart $1 done\"&#125;# 这里 format 定义输出的日志格式, read类似程序里的scan(将输入读取到指定变量的意思)inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %Xe %w %f' \\ -e DELETE,CREATE --excludei *.* $SRCDIR/* | while read DATE TIME EVENT DIR FILE; doRDIR=$&#123;DIR%/&#125;dir=$&#123;RDIR##*/&#125;echo \"notify $EVENT:$dir-$FILE\" # if [ \"CLOSE_WRITEXCLOSE\" == \"$EVENT\" ] #CLOSE事件不止一次发生,并且暂时不知道怎么判断文件上传结束if [ \"EOF\" == \"$FILE\" ] # 通过EOF文件标记上传结束then dorestart $dirfidone 说明: 略 操作: 每次上传完新程序文件,只需要删除对应目录下(自动生成的)EOF文件即可重启 执行: 不用 -d的原因是 -d -o 执行的时候出现了问题(提示日志文件权限之类的,没有细查…) 为什么不监听文件上传完成后重启 大文件断续上传,会产生好几个CREATE\\CLOSE事件,不好判断(主要是我也不会)文件是否真的完整上传完成. 上传时就在同一个目录下,删除一个EOF文件足够简单.并且这样还可以支持无更新重启(虽然上面脚本没支持) 动作缓冲,潜意识提醒你检查服务状态^0_0*","tags":[{"name":"sh","slug":"sh","permalink":"http://ipiao.top/tags/sh/"}]},{"title":"数字游戏","date":"2019-01-22T06:42:00.000Z","path":"2019/01/22/数字游戏/","text":"数学猜心魔术 让对方随便写一个五位数（五个数字各不相同，例如：37415） 用这五位数的五个数字再随意组成另外一个五位数 （例如：75314） 用这两个五位数相减（大数减小数，75314-37415=37899） 让对方记住得数中的任意一个数字，再把得数的其他数字告诉你 。（例如，我记住了“7”，把3899告诉你。） 你只要把对方告诉你的那几个数字一直相加到一位数，然后用9减就可以知道对方想的是什么数了 （你就把3899作一个简单的处理，3+8+9+9=29，所得的和还是一个两位数，你就继续处理2+9=11，继续处理1+1=2，最后得到一位数2以后，用最大的一位数9去减，9-2=7，那么你就猜到他心里记住的是7了。）","tags":[{"name":"数","slug":"数","permalink":"http://ipiao.top/tags/数/"},{"name":"魔术","slug":"魔术","permalink":"http://ipiao.top/tags/魔术/"}]},{"title":"scrapy爬虫-英语考研词汇","date":"2019-01-11T08:16:00.000Z","path":"2019/01/11/scrapy爬虫-英语考研词汇/","text":"scapy爬虫-考研英语词汇 之前都是用go语言爬虫的，学习了一点python，尝试着用scrapy框架爬虫 爬虫之前需要大致了解一下scarpy框架，官方文档实在看的累，找了一个中文翻译的简要了解了一下，地址是(http://www.scrapyd.cn/doc/165.html) 爬取的扇贝网的英语词汇(https://www.shanbay.com/wordbook/34/)， 虽然网页访问是要登录的，但是实际爬虫幷不需要。 1.扇贝网的文档结构十分统一 2.右上角的搜索框，搜一个单词，很容易就通过调试获取到单词信息接口 3.接口有次数限制，最好控制一下频率或者使用代理 于是，根据以上两点，很容易就能做到这个爬虫。而且由于结构的一致性，稍加修改，就能扩展到所有词汇的爬虫。 就英语考研词汇而言，内容有限，直接将最后的结果存储到json文件就可以了 具体代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121 # -*- coding: utf-8 -*-import scrapyimport timeimport jsonimport urllib3import randomclass WordbookSpider(scrapy.Spider): wl = [] failedwds = [] name = 'wordbook' allowed_domains = ['www.shanbay.com'] book = '34' file = None tmp_fp = None succ_fp = None successws = [] proxys = [ \"http://124.207.82.166:8008\" ] proxyManagers = [] def randproxy(self): return random.choice(self.proxyManagers) def start_requests(self): url = \"http://www.shanbay.com/wordbook/\" book = getattr(self, 'book', None) # 获取tag值，也就是爬取时传过来的参数 if book is not None: self.book = book url = url + self.book # 构造url file = getattr(self, 'file') if file is None: self.file = \"shanbei_wordbook_\" + self.book + \".json\" else: self.file = file tmpfile = \"shanbei_wordbook_\" + self.book + \"_tmp.json\" self.tmp_fp = open(tmpfile, 'a', encoding='utf-8') successfile = \"shanbei_wordbook_\" + self.book + \"_success.txt\" self.succ_fp = open(successfile, 'a', encoding='utf-8') # self.successws = self.succ_fp.readlines() for proxy in self.proxys: try: if proxy == \"\": pool = urllib3.PoolManager(num_pools=5) else: pool = urllib3.ProxyManager(proxy_url=proxy, num_pools=5) except Exception as e: print(\"can not conn:\", proxy, e) continue self.proxyManagers.append(pool) yield scrapy.Request(url, self.parse) # 发送请求爬取参数内容 def parse(self, response): ll = response.xpath('//*[@id=\"wordbook-wordlist-container\"]') for l in ll: wa = l.css('a::attr(href)').extract() for w in wa: next_page = response.urljoin(w) + \"?page=1\" yield scrapy.Request(next_page, callback=self.parsewds) # 避免一次性操作失败,可以分文件存储或者每一次查找到结果后存储到临时文件,最后统一处理格式 def parsewds(self, response): ll = response.xpath('/html/body/div[3]/div/div[1]/div[2]/div/table') wl = ll.xpath(\"//td[@class='span2']/strong//text()\").extract() for w in wl: if w not in self.successws: # print(w) self.searchword(w) time.sleep(0.001) # pass if len(wl) &gt; 1: time.sleep(1) ss = response.url.split('page=') page = int(ss[len(ss)-1]) next_page = ss[0] + \"page=\" + str(page+1) yield scrapy.Request(next_page, callback=self.parsewds) def searchword(self, w, first=True): r = self.randproxy().request(\"GET\", self.makesearchpath(w), retries=2) resp = json.loads(r.data, encoding=\"utf-8\") # resp = requests.get(self.makesearchpath(w)).json(encoding=\"utf-8\") print(resp) if resp['status_code'] == 0: data = resp['data'] data['word'] = w self.succ_fp.write(w) self.succ_fp.write(\"\\n\") self.wl.append(data) json.dump(data, self.tmp_fp, ensure_ascii=False) self.tmp_fp.write(\",\\n\") else: if first: self.searchword(w) else: self.failedwds.append(w) print(data) def makesearchurl(self, w): tm = int(time.time()*1000) url = \"/api/v1/bdc/search/?version=2&amp;word=&#123;&#125;&amp;_=&#123;&#125;\".format(w, tm) return url def makesearchpath(self, w): tm = int(time.time()*1000) path = \"http://www.shanbay.com/api/v1/bdc/search/?version=2&amp;word=&#123;&#125;&amp;_=&#123;&#125;\".format(w, tm) return path def close(self, spider, reason): self.wl.sort(key=lambda w: w['word'].lower()) fp = open(self.file, 'w', encoding='utf-8') json.dump(self.wl, fp, ensure_ascii=False, indent=4) print(\"failed words\", self.failedwds) fp.close() super().close(spider, reason) 运行 1 scrapy crawl wordbook -a book=34 全部过程 12345678910 #### 安装包pip install scrapy#### 创建项目scrapy startproject xxx#### 生成爬虫文件scrapy genspider -t basic wordbook https://www.shanbay.com/wordbook/#### 写代码#### 执行scrapy crawl wordbook -a book=34","tags":[{"name":"python","slug":"python","permalink":"http://ipiao.top/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://ipiao.top/tags/爬虫/"}]},{"title":"Leetcode 31-40","date":"2018-12-29T10:22:00.000Z","path":"2018/12/29/Leetcode-31-40/","text":"31. 下一个排列 实现获取下一个排列的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。 如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。 必须原地修改，只允许使用额外常数空间。 以下是一些例子，输入位于左侧列，其相应输出位于右侧列。1,2,3 → 1,3,23,2,1 → 1,2,31,1,5 → 1,5,1 解: 重点在于下一个的规则 code 12345678910111213141516171819202122232425262728293031323334 func nextPermutation(nums []int) &#123; for i:=len(nums) -1; i&gt;0; i-- &#123; if nums[i] &gt; nums[i-1]&#123; ind:=i for j:=i+1;j&lt;len(nums);j++&#123; if nums[j]&gt;nums[i-1] &amp;&amp; nums[j] &lt;= nums[ind]&#123; ind = j &#125; &#125; swap(nums, ind, i-1) reverse(nums[i:]) return &#125; &#125; reverse(nums)&#125;func reverse(nums []int) &#123; i := 0 j := len(nums) -1 for i &lt; j &#123; swap(nums,i,j) i++; j--; &#125;&#125;func swap(nums []int,i ,j int)&#123; tmp := nums[i] nums[i] = nums[j] nums[j] = tmp&#125; 32. 最长有效括号 给定一个只包含 ‘(‘ 和 ‘)’ 的字符串，找出最长的包含有效括号的子串的长度。 code 1234567891011121314151617181920212223 func longestValidParentheses(s string) int &#123; bytes := []byte(s) if len(bytes) &lt; 2 &#123; return 0 &#125; lengthList := make([]int, len(bytes)) var max int for i := 1; i &lt; len(bytes); i++ &#123; if bytes[i] == ')' &#123; j := i - lengthList[i-1] - 1 if j &gt;= 0 &amp;&amp; bytes[j] == '(' &#123; lengthList[i] = lengthList[i-1] + 2 if j-1 &gt;= 0 &#123; lengthList[i] += lengthList[j-1] &#125; &#125; &#125; if lengthList[i] &gt; max &#123; max = lengthList[i] &#125; &#125; return max&#125; 33. 搜索旋转排序数组 假设按照升序排序的数组在预先未知的某个点上进行了旋转。( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。你可以假设数组中不存在重复的元素。你的算法时间复杂度必须是 O(log n) 级别。 code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 func search(nums []int, target int) int &#123; length := len(nums) if length == 0 &#123; return -1 &#125; if length == 1 &#123; if nums[0] != target &#123; return -1 &#125; return 0 &#125; return search1(nums, 0, length-1, target)&#125;func search1(nums []int, left, right, target int) int &#123; if left &gt; right &#123; return -1 &#125; if left == right &#123; if nums[left] == target &#123; return left &#125; return -1 &#125; mid := left + (right-left)/2 if nums[mid] == target &#123; return mid &#125; if nums[left] &lt; nums[mid] &amp;&amp; nums[left] &lt;= target &amp;&amp; nums[mid] &gt; target &#123; return binarySearch(nums, left, mid-1, target) &#125; if nums[right] &gt; nums[mid] &amp;&amp; nums[mid] &lt; target &amp;&amp; nums[right] &gt;= target &#123; return binarySearch(nums, mid+1, right, target) &#125; if nums[left] &gt; nums[mid] &#123; return search1(nums, left, mid-1, target) &#125; if nums[right] &lt; nums[mid] &#123; return search1(nums, mid+1, right, target) &#125; return -1&#125;func binarySearch(nums []int, left, right, target int) int &#123; if left &gt; right &#123; return -1 &#125; mid := left + (right-left)/2 if nums[mid] == target &#123; return mid &#125; if target &lt; nums[mid] &#123; return binarySearch(nums, left, mid-1, target) &#125; return binarySearch(nums, mid+1, right, target)&#125; 34. 在排序数组中查找元素的第一个和最后一个位置 给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。你的算法时间复杂度必须是 O(log n) 级别。如果数组中不存在目标值，返回 [-1, -1]。 code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970 func searchRange(nums []int, target int) []int &#123; length := len(nums) if length == 0 || length == 1 &amp;&amp; nums[0] != target &#123; return []int&#123;-1, -1&#125; &#125; return searchRangeI(nums, 0, length-1, target)&#125;func searchRangeI(nums []int, left, right, target int) (ret []int) &#123; length := len(nums) if length == 0 || left &gt; right &#123; return []int&#123;-1, -1&#125; &#125; if left == right &#123; if nums[left] == target &#123; return []int&#123;left, left&#125; &#125; return []int&#123;-1, -1&#125; &#125; mid := left + (right-left)/2 if nums[mid] == target &#123; lower := findLower(nums, left, mid, target) upper := findUpper(nums, mid, right, target) return []int&#123;lower, upper&#125; &#125; else if nums[mid] &lt; target &#123; return searchRangeI(nums, mid+1, right, target) &#125; return searchRangeI(nums, left, mid-1, target)&#125;func findLower(nums []int, left, right, target int) int &#123; length := len(nums) if length == 0 || left &gt; right &#123; return -1 &#125; if left == right &#123; if nums[right] == target &#123; return right &#125; return -1 &#125; mid := left + (right-left)/2 if nums[mid] == target &#123; if mid &gt; left &amp;&amp; nums[mid-1] == target &#123; return findLower(nums, left, mid-1, target) &#125; return mid &#125; return findLower(nums, mid+1, right, target)&#125;func findUpper(nums []int, left, right, target int) int &#123; length := len(nums) if length == 0 || left &gt; right &#123; return -1 &#125; if left == right &#123; if nums[left] == target &#123; return left &#125; return -1 &#125; mid := left + (right-left)/2 if nums[mid] == target &#123; if mid &lt; right &amp;&amp; nums[mid+1] == target &#123; return findUpper(nums, mid+1, right, target) &#125; return mid &#125; return findUpper(nums, left, mid-1, target)&#125; 35. 搜索插入位置 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。你可以假设数组中无重复元素。 code 123456789101112131415161718192021222324252627 func searchInsert(nums []int, target int) int &#123; if len(nums) == 0&#123; nums = append(nums, target) return 0 &#125; return find(nums, 0, len(nums)-1, target)&#125;func find(nums []int, left, right ,target int) int&#123; if left == right&#123; if nums[left] &gt;= target&#123; return left &#125;else&#123; return right+1 &#125; &#125; mid := left + (right - left)/2 if nums[mid] == target&#123; return mid &#125; if nums[mid] &gt; target&#123; return find(nums, left, mid, target) &#125; return find(nums, mid+1, right, target)&#125; 36. 有效的数独 判断一个 9x9 的数独是否有效。只需要根据以下规则，验证已经填入的数字是否有效即可。数字 1-9 在每一行只能出现一次。数字 1-9 在每一列只能出现一次。数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。上图是一个部分填充的有效的数独。数独部分空格内已填入了数字，空白格用 ‘.’ 表示。 code 12345678910111213141516171819202122232425262728293031323334353637383940 func isValidSudoku(board [][]byte) bool &#123; rows := [9][9]byte&#123;&#125; squars := [9][9]byte&#123;&#125; list := [9][9]byte&#123;&#125; for i, sb := range board &#123; for j := range sb &#123; rows[j][i] = sb[j] squars[(i/3)*3+(j/3)][(i%3)*3+(j%3)] = sb[j] list[i][j] = sb[j] &#125; &#125; for _, row := range list &#123; if hasRepeted(row) &#123; return false &#125; &#125; for _, row := range rows &#123; if hasRepeted(row) &#123; return false &#125; &#125; for _, row := range squars &#123; if hasRepeted(row) &#123; return false &#125; &#125; return true&#125;func hasRepeted(bs [9]byte) bool &#123; for i := 0; i &lt; len(bs)-1; i++ &#123; for j := i + 1; j &lt; len(bs); j++ &#123; if bs[i] != '.' &amp;&amp; bs[i] == bs[j] &#123; return true &#125; &#125; &#125; return false&#125; 37. 解数独 编写一个程序，通过已填充的空格来解决数独问题。一个数独的解法需遵循如下规则：数字 1-9 在每一行只能出现一次。数字 1-9 在每一列只能出现一次。数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。空白格用 ‘.’ 表示。 一个数独。 答案被标成红色。Note:给定的数独序列只包含数字 1-9 和字符 ‘.’ 。你可以假设给定的数独只有唯一解。给定数独永远是 9x9 形式的。 解: 暴力递归 38. 报数 报数序列是一个整数序列，按照其中的整数的顺序进行报数，得到下一个数。其前五项如下： 1 11 21 1211 1112211 被读作 “one 1” (“一个一”) , 即 11。11 被读作 “two 1s” (“两个一”）, 即 21。21 被读作 “one 2”, “one 1” （”一个二” , “一个一”) , 即 1211。给定一个正整数 n（1 ≤ n ≤ 30），输出报数序列的第 n 项。注意：整数顺序将表示为一个字符串。 code 1234567891011121314151617181920 func countAndSay(n int) string &#123; if n == 1 &#123; return \"1\" &#125; base := countAndSay(n - 1) i := 0 count := 1 ret := \"\" for j := 1; j &lt; len(base); j++ &#123; if base[j] == base[i] &#123; count++ &#125; else &#123; ret += fmt.Sprint(count, string(base[i])) i = j count = 1 &#125; &#125; ret += fmt.Sprint(count, string(base[i])) return ret&#125; 39. 组合总和 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的数字可以无限制重复被选取。说明：所有数字（包括 target）都是正整数。解集不能包含重复的组合。 code 12345678910111213141516171819202122232425262728 func combinationSum(candidates []int, target int) [][]int &#123; sort.Ints(candidates) return cbs(candidates,0, target)&#125;func cbs(nums []int,start, target int) [][]int&#123; if target &lt;= 0 || nums[start] &gt; target&#123; return nil &#125; ret := [][]int&#123;&#125; if nums[start] == target&#123; ret = append(ret, []int&#123;nums[start]&#125;) return ret &#125; rs := cbs(nums, start, target-nums[start]) for _,r1:=range rs&#123; nr := make([]int, len(r1)+1) nr[0] = nums[start] copy(nr[1:], r1) ret = append(ret, nr) &#125; if start &lt; len(nums)-1&#123; ret = append(ret, cbs(nums, start+1, target)...) &#125; return ret&#125; 40. 组合总和 II 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的每个数字在每个组合中只能使用一次。说明：所有数字（包括目标数）都是正整数。解集不能包含重复的组合。 code 123456789101112131415161718192021222324252627 func combinationSum2(candidates []int, target int) [][]int &#123; sort.Ints(candidates) return DFS(candidates, 0, target, []int&#123;&#125;, [][]int&#123;&#125;)&#125;func DFS(candidates []int, start int, target int, solution []int, results [][]int) (rets [][]int) &#123; rets = results if target &lt; 0 &#123; return &#125; if target == 0 &#123; rets = append(rets, solution) return &#125; for i := start; i &lt; len(candidates); i++ &#123; if i &gt; start &amp;&amp; candidates[i] == candidates[i-1] &#123; continue &#125; candidate := candidates[i] repliaSolution := make([]int, len(solution)) copy(repliaSolution, solution) repliaSolution = append(repliaSolution, candidate) rets = DFS(candidates, i+1, target-candidate, repliaSolution, rets) repliaSolution = repliaSolution[:len(repliaSolution)-1] &#125; return&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://ipiao.top/tags/leetcode/"}]},{"title":"Leetcode 21-30","date":"2018-12-27T07:17:00.000Z","path":"2018/12/27/Leetcode-21-30/","text":"21. 合并两个有序链表 将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。示例：输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 code 123456789101112131415161718192021222324252627 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode &#123; if l1 == nil &#123; return l2 &#125; if l2 == nil &#123; return l1 &#125; var root = new(ListNode) if l1.Val &lt; l2.Val&#123; root.Val = l1.Val l1 = l1.Next &#125;else&#123; root.Val = l2.Val l2 = l2.Next &#125; if l1 !=nil || l2!=nil&#123; root.Next = mergeTwoLists(l1, l2) &#125; return root&#125; 22. 括号生成 给出 n 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且有效的括号组合。例如，给出 n = 3，生成结果为：[ “((()))”, “(()())”, “(())()”, “()(())”, “()()()”] code 123456789101112131415161718 func generateParenthesis(n int) []string &#123; var ans = []string&#123;&#125; generate(&amp;ans, \"\", 0, 0, n) return ans&#125;func generate(ans *[]string,cur string,l int, r int, max int) &#123; if len(cur) == max*2&#123; *ans = append(*ans, cur) &#125; if l &lt; max&#123; generate(ans, cur + \"(\", l+1, r, max) &#125; if r &lt; l&#123; generate(ans, cur + \")\", l, r+1, max) &#125;&#125; 23. 合并K个排序链表 合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。 code 123456789101112131415161718 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func mergeKLists(lists []*ListNode) *ListNode &#123; if len(lists) == 0 &#123; return nil &#125; if len(lists) == 1&#123; return lists[0] &#125; return mergeTwoLists(mergeKLists(lists[:len(lists)/2]), mergeKLists(lists[len(lists)/2:]))&#125; 24. 两两交换链表中的节点 给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。示例:给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3.说明:你的算法只能使用常数的额外空间。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 code 1234567891011121314151617 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func swapPairs(head *ListNode) *ListNode &#123; if head == nil || head.Next == nil&#123; return head &#125; p := head head = head.Next p.Next = swapPairs(head.Next) head.Next = p return head&#125; 25. k个一组翻转链表 给出一个链表，每 k 个节点一组进行翻转，并返回翻转后的链表。k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么将最后剩余节点保&gt; 持原有顺序。示例 :给定这个链表：1-&gt;2-&gt;3-&gt;4-&gt;5当 k = 2 时，应当返回: 2-&gt;1-&gt;4-&gt;3-&gt;5当 k = 3 时，应当返回: 3-&gt;2-&gt;1-&gt;4-&gt;5说明 :你的算法只能使用常数的额外空间。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 code 123456789101112131415161718192021222324252627282930313233343536373839404142434445 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func reverseKGroup(head *ListNode, k int) *ListNode &#123; if k == 1&#123; return head &#125; fake := &amp;ListNode&#123;Next: head&#125; p := fake for p != nil&#123; p.Next = reverseKNodes(p.Next, k) for i:=0; p!=nil &amp;&amp; i&lt;k; i++&#123; p = p.Next &#125; &#125; return fake.Next&#125;func reverseKNodes(head *ListNode, k int) *ListNode &#123; end := head for end != nil &amp;&amp; k&gt;0&#123; // end 是结束后一个 end = end.Next k-- &#125; if k &gt; 0&#123; return head &#125; var qNode *ListNode var ret = end var node = head for node != end &#123; qNode = node.Next node.Next = ret ret = node node = qNode &#125; return ret&#125; 26. 删除排序数组中的重复项 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 code 1234567891011121314 func removeDuplicates(nums []int) int &#123; if len(nums) &lt;= 1&#123; return len(nums) &#125; newLen:=1 base:=nums[0] for i:=1; i&lt;len(nums); i++&#123; if nums[i] != base&#123; nums[newLen],newLen,base = nums[i],newLen+1,nums[i] &#125; &#125; return newLen&#125; 27. 移除元素 给定一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val 的元素，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 code 123456789101112 func removeElement(nums []int, val int) int &#123; ind:=0 ret:=0 for i:=range nums&#123; if nums[i] != val&#123; ret++ nums[ind] = nums[i] ind++ &#125; &#125; return ret&#125; 28. 实现strStr() 给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。 解: 经典 KMP 算法 code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546 func strStr(haystack string, needle string) int &#123; if needle == \"\"&#123; return 0 &#125; return kmpIndex([]byte(haystack), []byte(needle))&#125;func kmpIndex(s, p []byte) int &#123; i := 0 j := 0 next := getNext(p) for i &lt; len(s) &amp;&amp; j &lt; len(p) &#123; if j == -1 || s[i] == p[j] &#123; i++ j++ &#125; else &#123; j = next[j] &#125; &#125; if j == len(p) &#123; return i - j &#125; return -1&#125;func getNext(ms []byte) []int &#123; length := len(ms) next := make([]int, length) next[0] = -1 k := -1 j := 0 for j &lt; length-1 &#123; if k == -1 || ms[j] == ms[k] &#123; j++ k++ if ms[j] != ms[k] &#123; next[j] = k &#125; else &#123; next[j] = next[k] &#125; &#125; else &#123; k = next[k] &#125; &#125; return next&#125; 29. 两数相除 给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。返回被除数 dividend 除以除数 divisor 得到的商。示例 1:输入: dividend = 10, divisor = 3输出: 3示例 2:输入: dividend = 7, divisor = -3输出: -2说明:被除数和除数均为 32 位有符号整数。除数不为 0。我们的环境只能存储 32 位有符号整数，其数值范围是 [−231, 231 − 1]。本题中，如果除法结果溢出，则返回 231 − 1。 解: 分治法 code 12345678910111213141516171819202122232425262728293031323334353637383940 func divide(dividend int, divisor int) int &#123; if dividend &lt; 0&#123; if dividend &gt; math.MinInt32&#123; if divisor == math.MinInt32&#123; return 0 &#125;else&#123; return divide(0-dividend, 0-divisor) &#125; &#125;else&#123; if divisor == math.MinInt32&#123; return 1 &#125;else if divisor == -1&#123; return math.MaxInt32 &#125; else&#123; if divisor &gt; 0&#123; return divide(divisor+dividend, divisor)-1 &#125;else&#123; return divide(dividend-divisor, divisor)+1 &#125; &#125; &#125; &#125; ret := 0 if divisor &gt; 0&#123; sum := divisor for sum &lt;= dividend&#123; ret++ sum += divisor &#125; &#125;else&#123; sum := 0-divisor for sum &lt;= dividend &#123; ret-- sum -= divisor &#125; &#125; return ret&#125; 30. 与所有单词相关联的字串 给定一个字符串 s 和一些长度相同的单词 words。在 s 中找出可以恰好串联 words 中所有单词的子串的起始位置。 子串要与 words 中的单词完全匹配，中间不能有其他字符，但不需要考虑 words 中单词串联的顺序。 示例 1: 输入: s = “barfoothefoobarman”, words = [“foo”,”bar”]输出: [0,9]解释: 从索引 0 和 9 开始的子串分别是 “barfoor” 和 “foobar” 。输出的顺序不重要, [9,0] 也是有效答案。示例 2: 输入: s = “wordgoodstudentgoodword”, words = [“word”,”student”]输出: [] code 12345678910111213141516171819202122232425262728293031323334353637383940414243 func findSubstring(s string, words []string) []int &#123; if len(s) == 0|| len(words) == 0&#123; return nil &#125; m1 := make(map[string]int) for _,word:=range words&#123; m1[word] += 1 &#125; ret := []int&#123;&#125; sl := len(words[0]) for i:=0; i&lt;sl; i++&#123; cm := make(map[string]int) c := 0 ind := i for st:=i; st&lt;len(s)-len(words)*sl+1; &#123; w := s[ind:ind+sl] if wc,ok := m1[w]; ok&#123; if cm[w] == wc &#123; cm[s[st:st+sl]]-=1 c-- st += sl &#125;else&#123; cm[w] ++ ind += sl if c == len(words)-1 &#123; ret =append(ret, st) cm[s[st:st+sl]]-=1 st += sl &#125;else&#123; c++ &#125; &#125; &#125;else&#123; c = 0 ind += sl st = ind cm = make(map[string]int) &#125; &#125; &#125; return ret&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://ipiao.top/tags/leetcode/"}]},{"title":"Leetcode 11-20","date":"2018-12-26T07:03:58.000Z","path":"2018/12/26/Leetcode-11-20/","text":"11. 盛最多水的容器 给定 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 说明：你不能倾斜容器，且 n 的值至少为 2。 解: 1.如果可以使用暴力，很多事情就变得简单了。 code 123456789101112131415 func maxArea(height []int) int &#123; s:=0 for i:=0 ;i&lt;len(height)-1;i++&#123; for j:=i+1;j&lt;len(height);j++&#123; a:=height[j]*(j-i) if height[j]&gt; height[i]&#123; a = height[i]*(j-i) &#125; if a &gt; s&#123; s = a &#125; &#125; &#125; return s&#125; 2.双指针法 code 12345678910111213141516171819 func maxArea(height []int) int &#123; l := len(height) s := 0 i,j := 0,l-1 for i&lt;j &#123; var s1 int if height[i]&lt;height[j]&#123; s1 = height[i]*(j-i) i++ &#125;else&#123; s1 = height[j]*(j-i) j-- &#125; if s1 &gt; s&#123; s = s1 &#125; &#125; return s&#125; 12. 整数转罗马数字 罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。 字符 数值I 1V 5X 10L 50C 100D 500M 1000例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个整数，将其转为罗马数字。输入确保在 1 到 3999 的范围内。 code 123456789101112131415 func intToRoman(num int) string &#123; var base = []int&#123;1000,900, 500,400, 100,90, 50,40, 10,9,5,4,1&#125; var strs = []string&#123;\"M\",\"CM\", \"D\",\"CD\",\"C\",\"XC\",\"L\",\"XL\",\"X\", \"IX\",\"V\",\"IV\",\"I\"&#125; ret := \"\" for i,b:=range base&#123; x := num/b num = num%b if x!=0&#123; for j:=0;j&lt;x;j++&#123; ret +=strs[i] &#125; &#125; &#125; return ret&#125; 13. 罗马数字转整数 罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。 字符 数值I 1V 5X 10L 50C 100D 500M 1000例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。 code 123456789101112131415 func romanToInt(s string) int &#123; var base = []int&#123;1000,900, 500,400, 100,90, 50,40, 10,9,5,4,1&#125; var strs = []string&#123;\"M\",\"CM\", \"D\",\"CD\",\"C\",\"XC\",\"L\",\"XL\",\"X\", \"IX\",\"V\",\"IV\",\"I\"&#125; ret:=0 for i:=0;i&lt; len(strs);&#123; if strings.HasPrefix(s,strs[i])&#123; ret+=base[i] s = s[len(strs[i]):] &#125;else&#123; i++ &#125; &#125; return ret&#125; 14. 最长公共前缀 编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，返回空字符串 “”。 code 123456789101112131415 func longestCommonPrefix(strs []string) string &#123; if len(strs)==0&#123; // 如果空，返回“” return \"\" &#125; base:=strs[0] // 选取第一个字符串作为对比基串 for i:=0;i&lt;len(base);i++&#123; b:=base[i] for j:=1;j&lt;len(strs);j++&#123; // 按索引对比 if i&gt;=len(strs[j]) || strs[j][i]!=b&#123; return base[:i] // 不想等就返回 &#125; &#125; &#125; return base&#125; 15. 三数之和 给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。注意：答案中不可以包含重复的三元组。例如, 给定数组 nums = [-1, 0, 1, 2, -1, -4]，满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]] 解: 1.分层循环 code 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 func threeSum(nums []int) [][]int &#123; sort.Ints(nums) ret := [][]int&#123;&#125; l:=len(nums) for i:=0;i&lt; l-2; i++&#123; if nums[i] &gt; 0 &#123; break &#125; if i&gt;0 &amp;&amp; nums[i] == nums[i-1]&#123; continue &#125; ts := twoSum(nums[i+1:], -nums[i]) for _,s:=range ts&#123; ret = append(ret, []int&#123;nums[i], s[0], s[1]&#125;) &#125; &#125; return ret&#125;func twoSum(nums []int, n int)[][]int&#123; ret := [][]int&#123;&#125; for i:=0; i&lt;len(nums)-1;i++&#123; if nums[i]&gt;n/2&#123; break &#125; if i&gt;0 &amp;&amp; nums[i] == nums[i-1]&#123; continue &#125; o,has := one(nums[i+1:], n-nums[i]) if has&#123; ret = append(ret, []int&#123;nums[i], o&#125;) &#125; &#125; return ret&#125;func one(nums []int,n int) (int,bool) &#123; end:=len(nums)-1 start:=0 if nums[start] == n&#123; return nums[start],true &#125; if nums[end] == n&#123; return nums[end],true &#125; for start&lt;end &#123; mid := (start+end)/2 if mid &gt; start&#123; if nums[mid] == n&#123; return nums[mid],true &#125; if nums[mid]&gt;n &#123; end = mid &#125;else&#123; start = mid &#125; &#125;else&#123; break &#125; &#125; return 0,false&#125; 2.三指针法 code 12345678910111213141516171819202122232425262728293031 func threeSum(nums []int) [][]int &#123; ret := [][]int&#123;&#125; sort.Ints(nums) for i:=0; i&lt;len(nums)-2; i++&#123; if nums[i] &gt; 0&#123; break &#125; if i &gt; 0 &amp;&amp; nums[i] == nums[i-1]&#123; continue &#125; j, k := i+1, len(nums)-1 for j&lt;k &#123; if j &gt; i+1 &amp;&amp; nums[j] == nums[j-1]&#123; j++ continue &#125; if nums[i] + nums[j] + nums[k] == 0&#123; ret = append(ret, []int&#123;nums[i], nums[j], nums[k]&#125;) j++ k-- &#125;else if nums[i] + nums[j] + nums[k] &gt; 0&#123; k-- &#125;else&#123; j++ &#125; &#125; &#125; return ret&#125; 16. 最接近的三数之和 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。例如，给定数组 nums = [-1，2，1，-4], 和 target = 1.与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2). 解: 三指针 code 1234567891011121314151617181920212223242526272829303132333435363738394041 func threeSumClosest(nums []int, target int) int &#123; sort.Ints(nums) det:=0 for i:=0; i&lt;len(nums)-2; i++&#123; if i == 0&#123; det = nums[0] + nums[1] + nums[len(nums)-1] - target &#125;else if nums[i] == nums[i-1]&#123; continue &#125; j, k := i+1, len(nums)-1 for j&lt;k &#123; if j &gt; i+1 &amp;&amp; nums[j] == nums[j-1]&#123; j++ continue &#125; temp := nums[i] + nums[j] + nums[k] - target if temp == 0&#123; return target &#125;else &#123; if abs(temp)&lt; abs(det) &#123; det = temp &#125; if temp &lt; 0&#123; j++ &#125;else&#123; k-- &#125; &#125; &#125; &#125; return det + target&#125;func abs(n int)int&#123; if n &lt; 0&#123; return -n &#125; return n&#125; 17. 电话号码的字母组合 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。 code 1234567891011121314151617181920212223242526272829 // 当然可以做复用 func letterCombinations(digits string) []string &#123; numMap := map[byte][]string&#123; '2': []string&#123;\"a\", \"b\", \"c\"&#125;, '3': []string&#123;\"d\", \"e\", \"f\"&#125;, '4': []string&#123;\"g\", \"h\", \"i\"&#125;, '5': []string&#123;\"j\", \"k\", \"l\"&#125;, '6': []string&#123;\"m\", \"n\", \"o\"&#125;, '7': []string&#123;\"p\", \"q\", \"r\", \"s\"&#125;, '8': []string&#123;\"t\", \"u\", \"v\"&#125;, '9': []string&#123;\"w\", \"x\", \"y\", \"z\"&#125;, &#125; if len(digits) == 0&#123; return nil &#125; fm := numMap[digits[0]] if len(digits) == 1&#123; return fm &#125; em := letterCombinations(digits[1:]) ret := []string&#123;&#125; for _,f := range fm&#123; for _,e:=range em&#123; ret = append(ret , f+e) &#125; &#125; return ret &#125; 18. 四数之和 给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。 注意： 答案中不可以包含重复的四元组。 示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为：[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]] 解:有一句mmp，不知当讲不当讲 code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 func fourSum(nums []int, target int) [][]int &#123; sort.Ints(nums) return kSum(nums, 4, target) &#125;// k&gt;=2func kSum(nums []int, k, target int)[][]int&#123; ret := [][]int&#123;&#125; if k == 2&#123; i, j := 0, len(nums)-1 for i &lt; j&#123; if nums[i] &gt; target/2&#123; break &#125; if i &gt; 0 &amp;&amp; nums[i] == nums[i-1]&#123; i++ continue &#125; if nums[i] + nums[j] == target&#123; ret = append(ret, []int&#123;nums[i], nums[j]&#125;) i++ j-- &#125;else if nums[i] + nums[j] &lt; target&#123; i++ &#125;else&#123; j-- &#125; &#125; &#125;else&#123; for i:=0; i&lt;len(nums) - k + 1; i++&#123; if nums[i] &gt; target/k &#123; break &#125; if i &gt; 0 &amp;&amp; nums[i] == nums[i-1]&#123; continue &#125; ts := kSum(nums[i+1:], k-1, target-nums[i]) for j:=range ts&#123; r := make([]int, k) r[0] = nums[i] copy(r[1:], ts[j]) ret = append(ret,r) &#125; &#125; &#125; return ret&#125; 19. 删除链表的倒数第N个节点 给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。 解: 从头节点与第n个节点同时移动，后一个节点移动至末尾，头节点将移动至倒数第n个节点 code 12345678910111213141516171819202122232425262728 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func removeNthFromEnd(head *ListNode, n int) *ListNode &#123; first := head for i := 1; i &lt; n; i++ &#123; first = first.Next &#125; var npNode *ListNode second := head for first.Next != nil &#123; first = first.Next npNode = second second = second.Next &#125; if npNode == nil &#123; return second.Next &#125; npNode.Next = second.Next return head&#125; 20. 有效的括号 给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。有效字符串需满足：左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。注意空字符串可被认为是有效字符串。 解: 经典栈 code 1234567891011121314151617181920 func isValid(s string) bool &#123; var match = map[byte]byte&#123; ')':'(', ']':'[', '&#125;':'&#123;', &#125; stack := []byte&#123;&#125; for _,b:= range []byte(s)&#123; switch b&#123; case '(','&#123;','[': stack = append(stack, b) case ')','&#125;',']': if len(stack) == 0 || stack[len(stack)-1] != match[b]&#123; return false &#125; stack = stack[:len(stack)-1] &#125; &#125; return len(stack) == 0&#125;","tags":[]},{"title":"AntDesign 圣诞节彩蛋","date":"2018-12-26T02:02:00.000Z","path":"2018/12/26/AntDesign-圣诞节彩蛋/","text":"Ho! Ho! Ho! 昨天，蚂蚁金服被喷了，原因是其开源带代码(https://github.com/ant-design/ant-design) 里埋下一个在圣诞节才触发的彩蛋。不凑巧的是，某部最近才发文，思想是“中国人不过洋节”。 于是,在第一个洋节就出了一堆彩蛋引发的事件，情节严重者就要失业、背锅。传称，“在代码里下毒”。AntDesign自然而然遭遇炮轰(https://github.com/ant-design/ant-design/issues/13848) 。 作为一名吃瓜群众，本着看戏不嫌热闹的精神，表示对开源者的支持。开源本来就是一项高度自由的活动。只不过不同于我们这类低等开发者，成功的开源框架有了大量的受众，或多或少会影响到这项受众的利益。但是在受众为开源框架锁惊叹，收到褒奖的时候，缺不见得有感恩戴德的表现。同时，某种习性让我们不由自主的找寻一个背锅侠，于是矛头指向开源者。但是，第一责任人不可否认的是开发者本人啊。且不说开发者的能力问题，开发本是开发者的职责，使用别人的框架是节省了不少成本的，甚至大多比自己做的好。在使用开源框架的时候，我想很多了都有承受bug的准备。可是，彩蛋和bug其实有什么区别呢。对于开发者，都是预料之外的问题罢了。","tags":[{"name":"吃瓜","slug":"吃瓜","permalink":"http://ipiao.top/tags/吃瓜/"}]},{"title":"Leetcode 6-10","date":"2018-12-25T07:14:00.000Z","path":"2018/12/25/Leetcode-6-10/","text":"6. Z 字形变换 将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。比如输入字符串 为”LEETCODEISHIRING” 行数为 3 时，排列如下（忽略下划线）： L _ C _ I _ R E T O E S I I G E _ D _ H _ N之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。请你实现这个将字符串进行指定行数变换的函数。 解: 这是一个有规律的图形阵，没什么可说的，直接套规律公式，避免一切花里胡哨 code 123456789101112131415161718192021222324252627282930 func convert(s string, numRows int) string &#123; if numRows == 1&#123; return s &#125; rs := []rune(s) l := len(rs) ret := []rune&#123;&#125; for i := 0; i &lt; numRows; i++ &#123; j := 0 for &#123; ind := (2*numRows-2)*j + i if ind &lt; l &#123; ret = append(ret, rs[ind]) &#125; else &#123; break &#125; if i != 0 &amp;&amp; i != numRows-1 &#123; ind2 := (2*numRows-2)*(j+1) - i if ind2 &lt; l &#123; ret = append(ret, rs[ind2]) &#125; else &#123; break &#125; &#125; j++ &#125; &#125; return string(ret)&#125; 7. 整数反转 给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转 code 123456789101112131415161718192021 func reverse(x int) int &#123; if x &lt; 0 &#123; return -(reverse(-x)) &#125; var y int32 = int32(x) bl := []int32&#123;&#125; for y &gt; 0 &#123; bl = append(bl, y%10) y = y / 10 &#125; var ret int32 for i := 0; i &lt; len(bl); i++ &#123; if ret &gt; (math.MaxInt32-bl[i])/10 &#123; return 0 &#125; ret = 10*ret + bl[i] &#125; return int(ret)&#125; 8. 字符串转换整数 (atoi) 请你来实现一个 atoi 函数，使其能将字符串转换成整数。 首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。 当我们寻找到的第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字组合起来，作为该整数的正负号；假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成整数。 该字符串除了有效的整数部分之后也可能会存在多余的字符，这些字符可以被忽略，它们对于函数不应该造成影响。 注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换。 在任何情况下，若函数不能进行有效的转换时，请返回 0。 说明： 假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 [−231, 231 − 1]。如果数值超过这个范围，qing返回 INT_MAX (231 − 1) 或 INT_MIN (−231) 。 code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 func myAtoi(str string) int &#123; var max = math.MaxInt32 bas := 1 // 乘子 nbs := make([]int,0) start:=false for i:=range str&#123; b:=str[i] if !start&#123; if b==' '&#123; continue &#125; if b == '-'&#123; bas = -1 start = true continue &#125; else if b=='+'&#123; start = true continue &#125; else if '0'&lt;=b &amp;&amp; b&lt;='9'&#123; start = true &#125;else&#123; return 0 &#125; &#125; if '0'&lt;=b &amp;&amp; b&lt;='9'&#123; nbs=append(nbs,int(b-'0')) &#125;else&#123; break &#125; &#125; if bas == -1&#123; max += 1 &#125; ret:=0 for i:=0;i&lt;len(nbs);i++&#123; if ret&gt;max/10 || (ret==max/10 &amp;&amp; nbs[i]&gt;max%10)&#123; ret = max break &#125; ret = ret*10 + nbs[i] &#125; return bas * ret&#125; 9. 回文数 判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 解: TIP:反转一半就可以了 code 1234567891011121314151617181920 func isPalindrome(x int) bool &#123; if x&lt;0&#123; return false &#125; if x==0&#123; return true &#125; var bl []int for x&gt;0&#123; bl = append(bl, x%10) x = x/10 &#125; l:=len(bl)/2 for i:=0;i&lt;l;i++&#123; if bl[i]!=bl[len(bl)-i-1]&#123; return false &#125; &#125; return true &#125; 10. 正则表达式匹配 给定一个字符串 (s) 和一个字符模式 (p)。实现支持 ‘.’ 和 ‘*’ 的正则表达式匹配。 ‘.’ 匹配任意单个字符。‘*’ 匹配零个或多个前面的元素。匹配应该覆盖整个字符串 (s) ，而不是部分字符串。 说明: s 可能为空，且只包含从 a-z 的小写字母。p 可能为空，且只包含从 a-z 的小写字母，以及字符 . 和 *。 解: 递归，很明显的 code 123456789101112131415161718192021222324252627282930313233 func isMatch(s string, p string) bool &#123; lp := len(p) ls := len(s) if ls == 0 &amp;&amp; lp == 0&#123; return true &#125; if ls !=0 &amp;&amp; lp == 0 &#123; return false &#125; if ls == 0 &amp;&amp; lp!=0 &#123; if p[lp-1] == '*'&#123; if lp == 1&#123; return true &#125; return isMatch(s, p[:lp-2]) &#125; return false &#125; if p[lp-1] == '.' || p[lp-1] == s[ls-1]&#123; return isMatch(s[:ls-1], p[:lp-1]) &#125; if p[lp-1] == '*'&#123; if isMatch(s, p[:lp-2])&#123; return true &#125; if (s[ls-1] == p[lp-2] || p[lp-2] == '.') &#123; return isMatch(s[:ls-1], p); &#125; return false; &#125; return false&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://ipiao.top/tags/leetcode/"}]},{"title":"Leetcode 3","date":"2018-12-24T09:03:00.000Z","path":"2018/12/24/Leetcode-3/","text":"字符串的排列 给定两个字符串 s1 和 s2，写一个函数来判断 s2 是否包含 s1 的排列。换句话说，第一个字符串的排列之一是第二个字符串的子串。注意： 输入的字符串只包含小写字母 两个字符串的长度都在 [1, 10,000] 之间 code 12345678910111213141516171819202122232425262728293031323334353637383940414243 func checkInclusion(s1 string, s2 string) bool &#123; if len(s1) &gt; len(s2) &#123; // 长度比较 return false &#125; v1 := sumstring(s1) i:=len(s1) v2 := sumstring(s2[:i]) for i &lt;= len(s2) &#123; if i &gt; len(s1)&#123; v2 += int(s2[i-1]) - int(s2[i-len(s1)-1]) &#125; if v1 == v2 &#123; // 在字符值相等的情况下才去判断是否是排列 if p(s1, s2[i-len(s1):i]) &#123; return true &#125; &#125; i++ &#125; return false&#125;func sumstring(s string) int &#123; // 计算string值 sum := 0 for i := range s &#123; sum += int(s[i]) &#125; return sum&#125;func p(b1, b2 string) bool &#123; // 判断是否是排列，也可以用排序算法降低空间复杂度 m1 := make(map[byte]int) m2 := make(map[byte]int) for i := range b1 &#123; m1[b1[i]] += 1 m2[b2[i]] += 1 &#125; for b, i := range m1 &#123; if m2[b] != i &#123; return false &#125; &#125; return true&#125;","tags":[{"name":"字符串","slug":"字符串","permalink":"http://ipiao.top/tags/字符串/"}]},{"title":"Leetcode 1-5","date":"2018-12-24T08:15:00.000Z","path":"2018/12/24/Leetcode-1-5/","text":"1. 两数之和 给定一个整数数组nums和一个目标值target，请你在该数组中找出和为目标值的那两个整数，并返回他们的数组下标。 解: 目的是要返回数组下标。 如果不考虑空间复杂度 如果考虑时间复杂度，就要保留一份数组备份，空间复杂度至少O(n),然后对数组进行排序，通过二分法查找，时间复杂度最优的是O(nlogn) code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 func twoSum(nums []int, target int) []int &#123;m := make(map[int]int) for i := 0; i &lt; len(nums); i++ &#123; another := target - nums[i] if _, ok := m[another]; ok &#123; return []int&#123;m[another], i&#125; &#125; m[nums[i]] = i &#125; return nil &#125; func twoSum(nums []int, target int) []int &#123; onum := make([]int, len(nums)) copy(onum, nums) // 保留备份 // Onlgn sort.Ints(nums) // 原数组排序 var find = func(anum []int, dest int) int &#123; // 二分查找数组中是否存在值为dest的元素 start := 0 end := len(anum) - 1 var mid int for start &lt; end-1 &#123; mid = (start + end) / 2 if anum[mid] == dest &#123; return mid &#125; if anum[mid] &gt; dest &#123; end = mid &#125; else &#123; start = mid &#125; &#125; if anum[start] == dest &#123; return start &#125; if anum[end] == dest &#123; return end &#125; return -1 &#125; // 遍历数组匹配 for i := range nums &#123; if cj := find(nums[i+1:], target-nums[i]); cj != -1 &#123; var ret = make([]int, 0) for j := range onum &#123; if onum[j] == nums[i] || onum[j] == nums[i+1+cj] &#123; ret = append(ret, j) &#125; &#125; return ret &#125; &#125; return nil &#125; 2. 两数相加 给出两个非空的链表用来表示两个非负的整数。其中，它们各自的位数是按照逆序的方式存储的，并且它们的每个节点只能存储一位数字。如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。您可以假设除了数字0之外，这两个数都不会以0开头。 解: 注意的只有两点 进位 链表遍历到最后做长度判断和拼接 code 123456789101112131415161718192021222324252627 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode &#123; if l1 == nil&#123; return l2 &#125; if l2 == nil&#123; return l1 &#125; node := new(ListNode) sum := l1.Val + l2.Val node.Next = addTwoNumbers(l1.Next,l2.Next) if sum &lt;10&#123; node.Val = sum &#125;else&#123; node.Val = sum -10 node.Next = addTwoNumbers(node.Next, &amp;ListNode&#123;Val:1&#125;) &#125; return node&#125; 3. 无重复字符的最长子串 给定一个字符串，请你找出其中不含有重复字符的最长子串的长度 code 123456789101112131415161718 func lengthOfLongestSubstring(s string) int &#123; var bMap = make(map[rune]int) // 存储字符索引，用于判断重复 var startInd = 0 // 有效点开始 var maxLen = 0 // 长度 for i, r := range s &#123; ind,ok := bMap[r] if ok &amp;&amp; ind &gt;= startInd &#123; // 判断是否在有效区间内重复 startInd = ind + 1 // 如果是，直接修改起始有效索引，没有比较的必要 &#125;else&#123; l := i - startInd + 1 // 否则，每一步计算当前有效区间长度，避免临界问题 if l &gt; maxLen&#123; // 与已有最大长度比较，如果超过最大长度就更新 maxLen = l &#125; &#125; bMap[r] = i // 赋值覆盖 &#125; return maxLen&#125; 4. 寻找两个有序数组的中位数 给定两个大小为m和n的有序数组nums1和nums2请你找出这两个有序数组的中位数，并且要求算法的时间复杂度为O(log(m + n))。你可以假设nums1和nums2不会同时为空。 解：有序数组，要求时间复杂度是O(log)级别的，应该是要使用二分法的。但是直接的二分法似乎没有可行之路，逐步分析下，发现通过递归可以实现。 code 123456789101112131415161718192021222324252627282930313233343536373839404142 func findMedianSortedArrays(nums1 []int, nums2 []int) float64 &#123; total := len(nums1) + len(nums2) if total%2 == 1 &#123; return float64(findKthNum(nums1, nums2, total/2+1)) &#125; else &#123; return 0.5 * float64(findKthNum(nums1, nums2, total/2)+findKthNum(nums1, nums2, total/2+1)) &#125;&#125;// 查找第k个数func findKthNum(nums1, nums2 []int, k int) int &#123; l1, l2 := len(nums1), len(nums2) if l1 &gt; l2 &#123; return findKthNum(nums2, nums1, k) &#125; if l1 == 0 &#123; return nums2[k-1] &#125; if k == 1 &#123; if nums1[0] &lt; nums2[0] &#123; return nums1[0] &#125; else &#123; return nums2[0] &#125; &#125; var pa, pb int if l1 &lt; k/2 &#123; pa = l1 &#125; else &#123; pa = k / 2 &#125; pb = k - pa // 比较较小端可以直接去除，不可能落在那里面，类二分 if nums1[pa-1] &lt; nums2[pb-1] &#123; return findKthNum(nums1[pa:], nums2, k-pa) &#125; else if nums2[pb-1] &lt; nums1[pa-1] &#123; return findKthNum(nums1, nums2[pb:], k-pb) &#125; else &#123; return nums1[pa-1] &#125;&#125; 5. 最长回文子串 给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 解: 硬算 code 123456789101112131415161718192021222324252627282930313233343536 func longestPalindrome(s string) string &#123; rs := []rune(s) l := len(rs) if l&lt;=1&#123; return s &#125; mp := rs[0:1] // 最长子串 for i := 0; i &lt; l-1; i++ &#123; temp1 := findPalindrome(rs, i, i) if len(temp1) &gt; len(mp) &#123; mp = temp1 &#125; if rs[i] == rs[i+1] &#123; temp2 := findPalindrome(rs, i, i+1) if len(temp2) &gt; len(mp) &#123; mp = temp2 &#125; &#125; &#125; return string(mp)&#125;func findPalindrome(rs []rune, si, ei int) []rune &#123; for si &gt; 0 &amp;&amp; ei &lt; len(rs)-1 &#123; if rs[si-1] == rs[ei+1] &#123; si-- ei++ &#125; else &#123; break &#125; &#125; return rs[si : ei+1]&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://ipiao.top/tags/leetcode/"}]},{"title":"Project Euler 1","date":"2018-12-24T07:28:00.000Z","path":"2018/12/24/Project-Euler-1/","text":"1.3的倍数和5的倍数 如果我们列出10以内所有3或5的倍数，我们将得到3、5、6和9，这些数的和是23。求1000以内所有3或5的倍数的和。 中学经典求和问题。计算 和=3的倍数和+5的倍数和-15的倍数和。 1234 3的倍数和 s1 = 333*334/2*3 = 1668335的倍数和 s2 = 199*200/2*5 = 9950015的倍数和 s3 = 66*67/2*15 = 33165s = 233168 code 1 ... 2.偶斐波那契数 斐波那契数列中的每一项都是前两项的和。由1和2开始生成的斐波那契数列前10项为：1, 2, 3, 5, 8, 13, 21, 34, 55, 89, … 考虑该斐波那契数列中不超过四百万的项，求其中为偶数的项之和。。","tags":[{"name":"pe","slug":"pe","permalink":"http://ipiao.top/tags/pe/"}]},{"title":"链表（一）","date":"2018-12-17T03:27:00.000Z","path":"2018/12/17/快慢指针法/","text":"快慢指针法 基本算法：https://www.cnblogs.com/songdechiu/p/6686520.html 扩展应用：https://www.cnblogs.com/hxsyl/p/4395794.html 判断一个链表是否存在环 code 1234567891011121314151617181920212223242526272829 /** * Definition for singly-linked list. * class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public boolean hasCycle(ListNode head) &#123; if(head==null) return false; if(head.next==null) return false; if(head.next.next==null) return false; ListNode slow=head; ListNode fast=head; while(fast!=null &amp;&amp; fast.next!=null)&#123; slow=slow.next; fast=fast.next.next; if(fast==slow)&#123; return true; &#125; &#125; return false; &#125;&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://ipiao.top/tags/leetcode/"},{"name":"链表","slug":"链表","permalink":"http://ipiao.top/tags/链表/"}]},{"title":"数——丑数","date":"2018-12-17T02:37:00.000Z","path":"2018/12/17/丑数计算/","text":"丑数计算 要求输入一个n数输出第n个丑数。丑数是素因子只有2,3,5,7… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123 package calimport ( \"math\" \"sort\")// Ugly 丑数，基础// base 素数数组 可以是 2,3,5|3,5,7type Ugly struct &#123; base []int // 基础素因子 bmul int // 基础素因子 乘积 cbase [][]int // 素因子对应的第i次计算次数 ranks [][]int // 素因子各次值排序&#125;// NewUgly 创建一个丑数计算基础func NewUgly(base []int) *Ugly &#123; sort.Ints(base) u := &amp;Ugly&#123; base: base, bmul: mul(base), &#125; u.calNext() return u&#125;// Get 获取第n个丑数func (u *Ugly) Get(n int) int &#123; for sumLen(u.ranks) &lt; n &#123; u.calNext() &#125; sl := 0 ret := 0 for i := range u.ranks &#123; li := len(u.ranks[i]) if sl+li &gt;= n &#123; ret = u.ranks[i][n-sl-1] break &#125; sl += li &#125; return ret&#125;// 第n次计算func (u *Ugly) calNext() &#123; var n = len(u.cbase) + 1 var bb = make([]int, len(u.base)) for i, b := range u.base &#123; bb[i] = maxc(pow(u.bmul, n), b) &#125; u.cbase = append(u.cbase, bb) // bn := make([]int, len(bb)) var rank []int min := pow(u.bmul, n-1) for autoAdd(bn, bb) &#123; pm := powmul(u.base, bn) if pm &gt; min &amp;&amp; pm &lt;= pow(u.bmul, n) &#123; rank = append(rank, pm) &#125; &#125; sort.Ints(rank) u.ranks = append(u.ranks, rank)&#125;// 多元排序自增// 返回是否还有下一个// ln下限func autoAdd(bn, ln []int) bool &#123; if bn[0] &lt; ln[0] &#123; bn[0]++ return true &#125; bn[0] = 0 if len(bn) == 1 &#123; return false &#125; return autoAdd(bn[1:], ln[1:])&#125;// 获取a以b为底的整数部分func maxc(a, b int) int &#123; return int(math.Log(float64(a)) / math.Log(float64(b)))&#125;// 获取乘积func mul(nums []int) int &#123; ret := 1 for _, n := range nums &#123; ret *= n &#125; return ret&#125;// 获取数组所有长度func sumLen(a [][]int) int &#123; l := 0 for _, aa := range a &#123; l += len(aa) &#125; return l&#125;func pow(x, n int) int &#123; if n == 0 &#123; return 1 &#125; ret := 1 for i := 0; i &lt; n; i++ &#123; ret *= x &#125; return ret&#125;func powmul(a, b []int) int &#123; var c = make([]int, len(a)) for i := range a &#123; c[i] = pow(a[i], b[i]) &#125; return mul(c)&#125; 测试代码 1234567 func TestUgly(t *testing.T) &#123; ug := NewUgly([]int&#123;2, 3, 5&#125;) n := ug.Get(1500) t.Log(n) t.Log(sumLen(ug.ranks)) // t.Log(ug.ranks)&#125; 返回结果,与网上一些博客给出的答案859963392有差距1个index，本人是以2作为第一个丑数的 1234567 go test -v -run 'TestUgly'=== RUN TestUgly--- PASS: TestUgly (0.00s) cal_test.go:32: 860934420 cal_test.go:33: 2254PASSok github.com/ipiao/metools/math/cal 0.006s 附上目标丑数附近的丑数序列 123 810000000 816293376 819200000 820125000 829440000 838860800 839808000 843750000849346560 850305600 854296875 859963392 860934420 864000000 874800000 878906250884736000 885735000 895795200 900000000 905969664 906992640 911250000","tags":[{"name":"博客迁移","slug":"博客迁移","permalink":"http://ipiao.top/tags/博客迁移/"},{"name":"leetcode","slug":"leetcode","permalink":"http://ipiao.top/tags/leetcode/"},{"name":"数","slug":"数","permalink":"http://ipiao.top/tags/数/"}]},{"title":"Go return,defer,panic执行分析","date":"2018-12-17T02:13:00.000Z","path":"2018/12/17/Go-return-defer-panic执行分析/","text":"基本原则 defer表示在函数结束前执行，并且多个defer是FILO的执行顺序 panic只会执行一个，recover的不算，后续的不会执行 return 返回与函数定义的是否带有返回参数是不一样的 return 和 defer 一个有返回值的函数，可以有以下2种定义: 123456789101112131415161718 // 不带有返回值参数func sum1(x,y int)int&#123; s := x+y return s // 假设返回参数是唯一变量s1，这里相当于显式的把s赋值给s1&#125; // 带有返回值参数func sum2(x,y int)(s int)&#123; s = x+y return // return的一定是s&#125;func main()&#123; s1 := sum1(1,2) s2 := sum2(1,2) print(s1) // 3 print(s2) // 3&#125; 这sum1和sum2结果是一样的，但是组合上defer，会有不一样结果: 12345678910111213141516171819202122 func sum3(x,y int)int&#123; s := x+y defer func()&#123; s += 2 // 第二步，对s进行自增运算，不影响s1的值 &#125;() return s // 第一步，把值赋予给s1&#125;func sum4(x,y int)(s int)&#123; s = x+y defer func()&#123; s += 2 // 第二步，对s进行自增运算，影响返回值s &#125;() return // 第一步，把值赋予给s本身(s2:=x+y;return s2是一样的)&#125;func main()&#123; s3 := sum3(1,2) s4 := sum4(1,2) println(s3) // 3 println(s4) // 5&#125; s3=3,s4=5，简单理解： 函数在开始执行的时候，先初始化了它的返回值，如果未声明，随机一个tempS,如果声明了，即s 在执行到return（返回标志）的时候赋值。 sum3函数先在执行到return时候，将tempS赋值为s，即3。由于s和tempS3是不同的变量，defer中的s+2就与tempS3无关。 sum4函数由于声明了返回变量s，return时候，如果是 return x+y，其实将x+y复制给s，如果直接return，可以理解为跳过了复制操作。在return之后的defer，s与sum3所谓的tempS3其实是一个，所以defer的操作是有效的。 补充,go多值返回:https://www.cntofu.com/book/3/zh/03.2.md defer 和 panic 12345678910111213141516171819202122232425262728 func main() &#123; var a int // fn1 defer func() &#123; a = 3 if err := recover(); err != nil &#123; a = 4 fmt.Println(\"++++\") f := err.(func() string) fmt.Println(err, f(), reflect.TypeOf(err).Kind().String()) &#125; else &#123; fmt.Println(\"fatal\") &#125; &#125;() // fn2 defer func() &#123; a = 2 if r := recover(); r != nil &#123; // 这里的recover()去掉感受一下效果 panic(r) &#125; panic(func() string &#123; return \"defer panic\" &#125;) &#125;() a = 1 panic(\"panic1\") // 这里的panic去掉感受一下效果 // panic(\"panic2\")&#125; 没什么好说的…","tags":[{"name":"go","slug":"go","permalink":"http://ipiao.top/tags/go/"},{"name":"博客迁移","slug":"博客迁移","permalink":"http://ipiao.top/tags/博客迁移/"}]},{"title":"Apns 推送表情问题","date":"2018-12-14T02:54:00.000Z","path":"2018/12/14/Apns-推送表情问题/","text":"Apns表情推送 1.常规的，服务端，尤其是go，发起apns推送是可以直接推送UTF-8表情的。 问题场景 发起apns推送，用户名中有emoji表情，推送结果显示不出来。 解决方案: 一顿操作以后，发现数据库字符是utf8mb4，字段字符集是utf8_general_ci。需要将字符集改成utf8_unicode_ci。有两种方式: 直接修改数据库配置，或者值修改相应字段的字符集 在程序中连接mysql的时候修改连接设置(基于对连接参数设置的支持)，charset=utf8mb4&amp;collation=utf8_unicode_ci。与前者的差异是，这种修改只是针对当前连接的，以及字符集修改是针对数据库的，会产生相应的效率问题。 问题补充: 发现在使用utf8_unicode_ci之后，数据库的插入出错(之前先插入缓存，所以问题没有及时发现)，所以在有插入需求的时候还是需要修改数据库的字段类型，这个时候发现utf8_unicode_ci就不是很好用，使用utf8mb4_general_ci 参考资料 apns文档 mysql Emoji存储方案 go 连接mysql参数设置","tags":[{"name":"apns","slug":"apns","permalink":"http://ipiao.top/tags/apns/"},{"name":"emoji","slug":"emoji","permalink":"http://ipiao.top/tags/emoji/"}]}]